{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1-step Forecasting with linear and non-linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import utils\n",
    "\n",
    "# Plot settings\n",
    "plt.rcParams['figure.figsize'] = (16, 8)\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "sns.set()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "    Unnamed: 0  ID               start          finish  drinks  comfortable  \\\n0            1   1 2018-02-06 16:20:00  2/6/2018 16:22       3     7.382609   \n31           2   1 2018-02-06 18:54:00  2/6/2018 18:58       0    14.382609   \n1            3   1 2018-02-06 20:08:00  2/6/2018 20:22       0    15.382609   \n2            4   1 2018-02-06 22:29:00  2/6/2018 22:46       0    21.382609   \n36           5   1 2018-02-07 10:52:00  2/7/2018 11:23       0   -11.617391   \n\n     stressed       down       calm   pressure  ...    cosT.1    sinT.1  \\\n0   -9.817391  10.843478 -37.791304   6.173913  ...  1.000000  0.000000   \n31  47.182609   7.843478   7.208696  10.173913  ...  0.892979  0.450098   \n1   12.182609  10.843478  20.208696  18.173913  ...  0.418660  0.908143   \n2   -5.817391  -2.156522   8.208696   5.173913  ...  0.108867  0.994056   \n36   5.182609   0.843478 -24.791304  -4.826087  ...  0.043619 -0.999048   \n\n     cos2T.1   sin2T.1    cosW.1    sinW.1  dayvar.1  beepvar.1  filter.1  \\\n0   1.000000  0.000000  1.000000  0.000000         1          4         0   \n31  0.594823  0.803857  0.997777  0.066647         1          5         0   \n1  -0.649448  0.760406  0.986795  0.161973         1          6         0   \n2  -0.976296  0.216440  0.978277  0.207302         1          7         0   \n36 -0.996195 -0.087156  0.777930  0.628351         2          1         0   \n\n    consec.1  \n0          1  \n31         2  \n1          3  \n2          4  \n36         7  \n\n[5 rows x 116 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>ID</th>\n      <th>start</th>\n      <th>finish</th>\n      <th>drinks</th>\n      <th>comfortable</th>\n      <th>stressed</th>\n      <th>down</th>\n      <th>calm</th>\n      <th>pressure</th>\n      <th>...</th>\n      <th>cosT.1</th>\n      <th>sinT.1</th>\n      <th>cos2T.1</th>\n      <th>sin2T.1</th>\n      <th>cosW.1</th>\n      <th>sinW.1</th>\n      <th>dayvar.1</th>\n      <th>beepvar.1</th>\n      <th>filter.1</th>\n      <th>consec.1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>2018-02-06 16:20:00</td>\n      <td>2/6/2018 16:22</td>\n      <td>3</td>\n      <td>7.382609</td>\n      <td>-9.817391</td>\n      <td>10.843478</td>\n      <td>-37.791304</td>\n      <td>6.173913</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>2</td>\n      <td>1</td>\n      <td>2018-02-06 18:54:00</td>\n      <td>2/6/2018 18:58</td>\n      <td>0</td>\n      <td>14.382609</td>\n      <td>47.182609</td>\n      <td>7.843478</td>\n      <td>7.208696</td>\n      <td>10.173913</td>\n      <td>...</td>\n      <td>0.892979</td>\n      <td>0.450098</td>\n      <td>0.594823</td>\n      <td>0.803857</td>\n      <td>0.997777</td>\n      <td>0.066647</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>1</td>\n      <td>2018-02-06 20:08:00</td>\n      <td>2/6/2018 20:22</td>\n      <td>0</td>\n      <td>15.382609</td>\n      <td>12.182609</td>\n      <td>10.843478</td>\n      <td>20.208696</td>\n      <td>18.173913</td>\n      <td>...</td>\n      <td>0.418660</td>\n      <td>0.908143</td>\n      <td>-0.649448</td>\n      <td>0.760406</td>\n      <td>0.986795</td>\n      <td>0.161973</td>\n      <td>1</td>\n      <td>6</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>1</td>\n      <td>2018-02-06 22:29:00</td>\n      <td>2/6/2018 22:46</td>\n      <td>0</td>\n      <td>21.382609</td>\n      <td>-5.817391</td>\n      <td>-2.156522</td>\n      <td>8.208696</td>\n      <td>5.173913</td>\n      <td>...</td>\n      <td>0.108867</td>\n      <td>0.994056</td>\n      <td>-0.976296</td>\n      <td>0.216440</td>\n      <td>0.978277</td>\n      <td>0.207302</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>5</td>\n      <td>1</td>\n      <td>2018-02-07 10:52:00</td>\n      <td>2/7/2018 11:23</td>\n      <td>0</td>\n      <td>-11.617391</td>\n      <td>5.182609</td>\n      <td>0.843478</td>\n      <td>-24.791304</td>\n      <td>-4.826087</td>\n      <td>...</td>\n      <td>0.043619</td>\n      <td>-0.999048</td>\n      <td>-0.996195</td>\n      <td>-0.087156</td>\n      <td>0.777930</td>\n      <td>0.628351</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 116 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading alcohol data\n",
    "train_df, test_df, data_raw_list = utils.load_alcohol()\n",
    "\n",
    "combined_data = []\n",
    "\n",
    "for i in range(len(train_df)):\n",
    "    train = train_df[i]\n",
    "    test = test_df[i]\n",
    "    # Combine both train and test sets since the initial split was 50/50\n",
    "    combined = pd.concat([train, test])\n",
    "    # Sort by date\n",
    "    combined['start'] = pd.to_datetime(combined['start'])\n",
    "    combined = combined.sort_values(by='start')\n",
    "    combined_data.append(combined)\n",
    "\n",
    "combined_data[0].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient included in study:\n",
      "[3, 5, 8, 11, 14, 15, 16, 24, 25, 26, 27, 31, 34, 35, 37, 39, 41, 42, 46, 50, 53, 54, 59, 63, 65, 66, 70, 72, 77]\n"
     ]
    },
    {
     "data": {
      "text/plain": "     Relax_lag  Irritable_lag  Worry_lag  Nervous_lag  Future_lag  \\\n222        2.0            3.0        2.0          2.0         1.0   \n219        2.0            1.0        3.0          2.0         1.0   \n212        2.0            2.0        2.0          1.0         1.0   \n218        1.0            1.0        1.0          2.0         1.0   \n184        2.0            1.0        2.0          2.0         1.0   \n\n     Anhedonia_lag  Tired_lag  Hungry_lag  Alone_lag  Angry_lag  \\\n222            1.0        1.0         2.0        1.0        2.0   \n219            1.0        2.0         3.0        1.0        1.0   \n212            1.0        2.0         3.0        1.0        3.0   \n218            2.0        2.0         2.0        1.0        1.0   \n184            1.0        2.0         2.0        1.0        1.0   \n\n     Social_offline_lag  Social_online_lag  Music_lag  Procrastinate_lag  \\\n222                 3.0                3.0        1.0                2.0   \n219                 3.0                3.0        5.0                3.0   \n212                 2.0                4.0        3.0                4.0   \n218                 2.0                4.0        3.0                2.0   \n184                 4.0                4.0        3.0                3.0   \n\n     Outdoors_lag  C19_occupied_lag  C19_worry_lag  Home_lag  beepvar_lag  \n222           1.0               1.0            1.0       5.0          1.0  \n219           1.0               3.0            2.0       5.0          2.0  \n212           1.0               2.0            3.0       5.0          3.0  \n218           1.0               2.0            2.0       5.0          1.0  \n184           2.0               3.0            2.0       5.0          3.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Relax_lag</th>\n      <th>Irritable_lag</th>\n      <th>Worry_lag</th>\n      <th>Nervous_lag</th>\n      <th>Future_lag</th>\n      <th>Anhedonia_lag</th>\n      <th>Tired_lag</th>\n      <th>Hungry_lag</th>\n      <th>Alone_lag</th>\n      <th>Angry_lag</th>\n      <th>Social_offline_lag</th>\n      <th>Social_online_lag</th>\n      <th>Music_lag</th>\n      <th>Procrastinate_lag</th>\n      <th>Outdoors_lag</th>\n      <th>C19_occupied_lag</th>\n      <th>C19_worry_lag</th>\n      <th>Home_lag</th>\n      <th>beepvar_lag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>222</th>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>219</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>212</th>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>218</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>184</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading covid data\n",
    "covid_train_x_list, covid_test_x_list, covid_train_y_list, covid_test_y_list = utils.patients_covid()\n",
    "\n",
    "covid_train_x_list[0].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Idiographic Models Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Predict craving\n",
    "\n",
    "# Make own splits\n",
    "def prepare_data_own(idx, combined_list, random_state):\n",
    "    # print('Patient ID:', combined_list[idx].iloc[0]['ID'])\n",
    "    X = combined_list[idx].drop(combined_list[idx].columns[range(0, 24)], axis=1).fillna(0)\n",
    "    y = combined_list[idx]['craving']\n",
    "\n",
    "    return train_test_split(X, y, test_size=0.3, random_state=random_state)\n",
    "\n",
    "\n",
    "def prepare_data(idx, train_list, test_list):\n",
    "    # print('Patient ID:', train_list[idx]['ID'][0])\n",
    "\n",
    "    X_train = train_list[idx].drop(train_list[idx].columns[range(0, 61)], axis=1).fillna(0)\n",
    "    y_train = train_list[idx]['craving']\n",
    "    X_test = test_list[idx].drop(test_list[idx].columns[range(0, 61)], axis=1).fillna(0)\n",
    "    y_test = test_list[idx]['craving']\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1 Elastic-Net Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_squared: 0.3105248292112299\n",
      "MAPE: 0.868046768759073\n",
      "RMSE: 20.394294809977133\n",
      "MAE: 16.71060148405697\n",
      "CORR: 0.5610027960444378\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = prepare_data(1, train_list=train_df, test_list=test_df)\n",
    "\n",
    "\n",
    "def elastic_net(train_x, train_y, test_x, test_y, vis):\n",
    "    X_train_loc = utils.standardize(train_x).fillna(0)\n",
    "    X_test_loc = utils.standardize(test_x).fillna(0)\n",
    "\n",
    "    l1_ratios = np.arange(0.01, 0.6, 0.05)\n",
    "    elastic_reg = lm.ElasticNetCV(alphas=np.arange(0.01, 20, 0.05), l1_ratio=l1_ratios, cv=5, max_iter=100000,\n",
    "                                  fit_intercept=True)\n",
    "    elastic_reg.fit(X_train_loc, train_y)\n",
    "    y_predicted_test = elastic_reg.predict(X_test_loc)\n",
    "    # print('--- Elastic-Net Results ---')\n",
    "    # print()\n",
    "    utils.eval_results(actual=test_y, predicted=y_predicted_test, show=vis)\n",
    "\n",
    "    return elastic_reg\n",
    "\n",
    "\n",
    "m = elastic_net(X_train, y_train, X_test, y_test, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 Linear SVM Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_squared: 0.3129085262202247\n",
      "MAPE: 0.8226982750899446\n",
      "RMSE: 20.359010065811535\n",
      "MAE: 15.75717512952631\n",
      "CORR: 0.5713817555748293\n"
     ]
    }
   ],
   "source": [
    "def linear_svm(train_x, train_y, test_x, test_y, vis, params):\n",
    "    X_train_loc = utils.standardize(train_x).fillna(0)\n",
    "    X_test_loc = utils.standardize(test_x).fillna(0)\n",
    "\n",
    "    clf = GridSearchCV(estimator=LinearSVR(), param_grid=params, scoring='neg_mean_absolute_error', cv=5)\n",
    "    clf.fit(X_train_loc, train_y)\n",
    "    # best_params = clf.best_params_\n",
    "    # print(best_params)\n",
    "    y_predicted_test = clf.predict(X_test_loc)\n",
    "\n",
    "    # print('--- Linear-SVM Results ---')\n",
    "    # print()\n",
    "    utils.eval_results(actual=test_y, predicted=y_predicted_test, show=vis)\n",
    "    return clf\n",
    "\n",
    "\n",
    "param = [\n",
    "    {'C': np.arange(0.1, 4, 0.1),\n",
    "     'epsilon': np.arange(6, 7, 0.1),\n",
    "     'loss': ['epsilon_insensitive'],\n",
    "     'fit_intercept': [True],\n",
    "     'max_iter': [10000]}]\n",
    "\n",
    "m = linear_svm(X_train, y_train, X_test, y_test, True, param)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3 K-NN Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_squared: 0.1254204616378809\n",
      "MAPE: 1.0122225548421209\n",
      "RMSE: 22.969367355995985\n",
      "MAE: 17.183673469387752\n",
      "CORR: 0.49538301761540343\n"
     ]
    }
   ],
   "source": [
    "def knn_reg(train_x, train_y, test_x, test_y, vis):\n",
    "    params = [\n",
    "        {'weights': ['uniform', 'distance'],\n",
    "         'n_neighbors': np.arange(2, 20, 1)}]\n",
    "\n",
    "    clf = GridSearchCV(estimator=KNeighborsRegressor(), param_grid=params, scoring='neg_mean_absolute_error', cv=5)\n",
    "    clf.fit(train_x, train_y)\n",
    "    #best_params = clf.best_params_\n",
    "    #print(best_params)\n",
    "\n",
    "    y_predicted_test = clf.predict(test_x)\n",
    "\n",
    "    # print('--- kNN Regression Results ---')\n",
    "    # print()\n",
    "    r2, rmse, mae = utils.eval_results(actual=test_y, predicted=y_predicted_test, show=vis)\n",
    "    return r2, rmse, mae\n",
    "\n",
    "\n",
    "m = knn_reg(X_train, y_train, X_test, y_test, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.4 XGBoost Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_squared: 0.15838669249167292\n",
      "MAPE: 0.8031469582675796\n",
      "RMSE: 22.53230775472528\n",
      "MAE: 16.368831303541146\n",
      "CORR: 0.49631329401780205\n"
     ]
    }
   ],
   "source": [
    "def xgboost_reg(train_x, train_y, test_x, test_y, vis):\n",
    "    # Very simple models work better here, since there are few datapoints\n",
    "    params = [\n",
    "        {'objective': ['reg:squarederror'],\n",
    "         'n_estimators': np.arange(1, 10, 1),\n",
    "         'eval_metric': ['mae'],\n",
    "         'max_depth': np.arange(1, 5, 1)}]\n",
    "\n",
    "    reg_xgb = GridSearchCV(xgb.XGBRegressor(), params, n_jobs=5, cv=5, scoring='neg_mean_absolute_error')\n",
    "    reg_xgb.fit(train_x, train_y)\n",
    "\n",
    "    #print(reg_xgb.best_params_)\n",
    "    y_predicted_test = reg_xgb.predict(test_x)\n",
    "\n",
    "    # print('--- XGBoost Regression Results ---')\n",
    "    # print()\n",
    "    utils.eval_results(actual=test_y, predicted=y_predicted_test, show=vis)\n",
    "    return reg_xgb\n",
    "\n",
    "\n",
    "m = xgboost_reg(X_train, y_train, X_test, y_test, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.5 Random Forests"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_squared: 0.2492853231605029\n",
      "MAPE: 0.7607219673686301\n",
      "RMSE: 21.280745146119063\n",
      "MAE: 15.681722611288938\n",
      "CORR: 0.5420361229167744\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "def random_forests(train_x, train_y, test_x, test_y, vis):\n",
    "    grid = [\n",
    "        {'n_estimators': [50, 70, 100],\n",
    "         'max_features': ['auto', 'sqrt'],\n",
    "         'max_depth': [5, 10, 15, 20],\n",
    "         'min_samples_split': [2, 4, 6],\n",
    "         'min_samples_leaf': [1],\n",
    "         'bootstrap': [True]}]\n",
    "\n",
    "    rf = GridSearchCV(RandomForestRegressor(), param_grid=grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "    rf.fit(train_x, train_y)\n",
    "    y_predicted_test = rf.predict(test_x)\n",
    "    # print(rf.best_params_)\n",
    "\n",
    "    utils.eval_results(actual=test_y, predicted=y_predicted_test, show=vis)\n",
    "\n",
    "    return rf\n",
    "\n",
    "\n",
    "m = random_forests(X_train, y_train, X_test, y_test, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.6 3-Layer LSTM RNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_squared: 0.054773748403972755\n",
      "MAPE: 0.9142236210668855\n",
      "RMSE: 23.879062089128087\n",
      "MAE: 21.370987144547033\n",
      "CORR: 0.5253341864787269\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import keras.layers as layer\n",
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "def lstm_rnn(train_x, train_y, test_x, test_y, vis):\n",
    "    X_train_loc = utils.standardize(train_x).fillna(0)\n",
    "    X_test_loc = utils.standardize(test_x).fillna(0)\n",
    "    train_x_val, train_y_val, test_x_val, test_y_val = X_train_loc.values, train_y.values, X_test_loc.values, test_y.values\n",
    "\n",
    "    train_x_val = train_x_val.reshape((train_x_val.shape[0], 1, train_x_val.shape[1]))\n",
    "    test_x_val = test_x_val.reshape((test_x_val.shape[0], 1, test_x_val.shape[1]))\n",
    "\n",
    "    # print(train_x_val.shape)\n",
    "    # print(test_x_val.shape)\n",
    "\n",
    "    model = Sequential([\n",
    "        layer.LSTM(40, return_sequences=True, input_shape=(train_x_val.shape[1], train_x_val.shape[2])),\n",
    "        layer.Dropout(0.25),\n",
    "        layer.LSTM(units=25, return_sequences=True),\n",
    "        layer.Dropout(0.20),\n",
    "        layer.LSTM(units=10, return_sequences=False),\n",
    "        layer.Dense(units=1, activation='linear'),\n",
    "    ])\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    model.fit(train_x_val, train_y_val, epochs=15, batch_size=4, verbose=0, shuffle=False)\n",
    "\n",
    "    y_predicted_test = model.predict(test_x_val)\n",
    "\n",
    "    utils.eval_results(actual=test_y, predicted=y_predicted_test.flatten(), show=vis)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "m = lstm_rnn(X_train, y_train, X_test, y_test, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.7 1-Layer LSTM RNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_squared: 0.08929869721259409\n",
      "MAPE: 0.9300090379333514\n",
      "RMSE: 23.438907026255826\n",
      "MAE: 21.216795440726315\n",
      "CORR: 0.5412689069328842\n"
     ]
    }
   ],
   "source": [
    "def one_lstm_rnn(train_x, train_y, test_x, test_y, vis):\n",
    "    X_train_loc = utils.standardize(train_x).fillna(0)\n",
    "    X_test_loc = utils.standardize(test_x).fillna(0)\n",
    "    train_x_val, train_y_val, test_x_val, test_y_val = X_train_loc.values, train_y.values, X_test_loc.values, test_y.values\n",
    "\n",
    "    train_x_val = train_x_val.reshape((train_x_val.shape[0], 1, train_x_val.shape[1]))\n",
    "    test_x_val = test_x_val.reshape((test_x_val.shape[0], 1, test_x_val.shape[1]))\n",
    "\n",
    "    # print(train_x_val.shape)\n",
    "    # print(test_x_val.shape)\n",
    "\n",
    "    model = Sequential([\n",
    "        layer.LSTM(64, return_sequences=True, input_shape=(train_x_val.shape[1], train_x_val.shape[2])),\n",
    "        layer.Dropout(0.25),\n",
    "        layer.Dense(units=1, activation='linear'),\n",
    "    ])\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    model.fit(train_x_val, train_y_val, epochs=15, batch_size=4, verbose=0, shuffle=False)\n",
    "\n",
    "    y_predicted_test = model.predict(test_x_val)\n",
    "\n",
    "    utils.eval_results(actual=test_y, predicted=y_predicted_test.flatten(), show=vis)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "m = one_lstm_rnn(X_train, y_train, X_test, y_test, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.8 MTGNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as f\n",
    "from torch_geometric_temporal.nn.recurrent.gconv_gru import GConvGRU\n",
    "\n",
    "\n",
    "class RecurrentGCN(torch.nn.Module):\n",
    "    def __init__(self, node_features, filters):\n",
    "        super(RecurrentGCN, self).__init__()\n",
    "        self.recurrent = GConvGRU(node_features, filters, 2)\n",
    "        self.linear = torch.nn.Linear(filters, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        h = self.recurrent(x, edge_index, edge_weight)\n",
    "        h = f.relu(h)\n",
    "        h = self.linear(h)\n",
    "        return h"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1 Evaluating Performance on Entire Dataset (Alcohol Data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000191F1EFCC10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000191ED911700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "---- Elastic-Net Results ----\n",
      "Average R_Squared: 0.194006559997254\n",
      "Average RMSE: 14.771363649360774\n",
      "Average MAE: 10.985510678456176\n",
      "---------------------------------\n",
      "---- Linear SVM Results ----\n",
      "Average R_Squared: 0.20004536629529546\n",
      "Average RMSE: 14.318375097090842\n",
      "Average MAE: 10.335261341439876\n",
      "---------------------------------\n",
      "---- XGBoost Results ----\n",
      "Average R_Squared: 0.12261621935718933\n",
      "Average RMSE: 15.382442588198774\n",
      "Average MAE: 10.944263945708332\n",
      "---------------------------------\n",
      "---- Random Forest Results ----\n",
      "Average R_Squared: 0.18846189894378887\n",
      "Average RMSE: 14.561648370470579\n",
      "Average MAE: 10.51607322501854\n",
      "---------------------------------\n",
      "---- LSTM Results ----\n",
      "Average R_Squared: 0.03646181577272716\n",
      "Average RMSE: 15.81945009011864\n",
      "Average MAE: 11.267651222011866\n",
      "---------------------------------\n",
      "---- 1-LSTM Results ----\n",
      "Average R_Squared: 0.02703671701323061\n",
      "Average RMSE: 15.954609348604139\n",
      "Average MAE: 11.486517695267736\n",
      "---------------------------------\n",
      "Included patient list:\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "\n",
    "def evaluate_models(train_list, test_list):\n",
    "    assert len(train_list) == len(test_list)\n",
    "    r2_elastic, r2_svm, r2_one_lstm, r2_xgb, r2_rf, r2_lstm, r2_mtgnn = ([] for _ in range(7))\n",
    "    rmse_elastic, rmse_svm, rmse_one_lstm, rmse_xgb, rmse_rf, rmse_lstm, rmse_mtgnn = ([] for _ in range(7))\n",
    "    mae_elastic, mae_svm, mae_one_lstm, mae_xgb, mae_rf, mae_lstm, mae_mtgnn = ([] for _ in range(7))\n",
    "\n",
    "    patient_ids = []\n",
    "    f = open(\"output_idiographic_a.txt\", \"a\")\n",
    "    f.write('- - - PER INDIVIDUAL RESULTS - - -\\n')\n",
    "    for x in range(len(train_list)):\n",
    "        # Build and evaluate a model for every single patient\n",
    "        train_x, test_x, train_y, test_y = prepare_data(x, train_list=train_list, test_list=test_list)\n",
    "        # Elastic-Net (baseline)\n",
    "        elastic = elastic_net(train_x, train_y, test_x, test_y, False)\n",
    "        r2, rmse, mae = utils.eval_results(test_y, elastic.predict(utils.standardize(test_x).fillna(0)), False)\n",
    "        # Elastic-Net metrics\n",
    "        patient_ids.append(train_list[x]['ID'][0])\n",
    "        r2_elastic.append(max(0, r2))\n",
    "        rmse_elastic.append(rmse)\n",
    "        mae_elastic.append(mae)\n",
    "\n",
    "        f.write(\"Patient ID: %s\\n\" % train_list[x]['ID'][0])\n",
    "        f.write('\\n')\n",
    "        f.write('--- Elastic-Net ---\\n')\n",
    "        f.write(\"R_squared: %s\\n\" % max(0, r2))\n",
    "        f.write(\"RMSE: %s\\n\" % rmse)\n",
    "        f.write(\"MAE: %s\\n\" % mae)\n",
    "        f.write('\\n')\n",
    "\n",
    "        # Linear-SVM\n",
    "\n",
    "        params = [\n",
    "            {'C': np.arange(0.1, 4, 0.1),\n",
    "             'epsilon': np.arange(6, 7, 0.1),\n",
    "             'loss': ['epsilon_insensitive'],\n",
    "             'fit_intercept': [True],\n",
    "             'max_iter': [10000]}]\n",
    "\n",
    "        svm = linear_svm(train_x, train_y, test_x, test_y, False, params)\n",
    "        r2, rmse, mae = utils.eval_results(test_y, svm.predict(utils.standardize(test_x).fillna(0)), False)\n",
    "        # Linear-SVM metrics\n",
    "        r2_svm.append(max(0, r2))\n",
    "        rmse_svm.append(rmse)\n",
    "        mae_svm.append(mae)\n",
    "\n",
    "        f.write('--- Linear-SVM ---\\n')\n",
    "        f.write(\"R_squared: %s\\n\" % max(0, r2))\n",
    "        f.write(\"RMSE: %s\\n\" % rmse)\n",
    "        f.write(\"MAE: %s\\n\" % mae)\n",
    "        f.write('\\n')\n",
    "\n",
    "        # XGBoost Regression\n",
    "        xgboost = xgboost_reg(train_x, train_y, test_x, test_y, False)\n",
    "        r2, rmse, mae = utils.eval_results(test_y, xgboost.predict(test_x), False)\n",
    "        # XGBoost metrics\n",
    "        r2_xgb.append(max(0, r2))\n",
    "        rmse_xgb.append(rmse)\n",
    "        mae_xgb.append(mae)\n",
    "\n",
    "        f.write('--- XGBoost ---\\n')\n",
    "        f.write(\"R_squared: %s\\n\" % max(0, r2))\n",
    "        f.write(\"RMSE: %s\\n\" % rmse)\n",
    "        f.write(\"MAE: %s\\n\" % mae)\n",
    "        f.write('\\n')\n",
    "\n",
    "        # RF\n",
    "        rf = random_forests(train_x, train_y, test_x, test_y, False)\n",
    "        r2, rmse, mae = utils.eval_results(test_y, rf.predict(test_x), False)\n",
    "        # RF metrics\n",
    "        r2_rf.append(max(0, r2))\n",
    "        rmse_rf.append(rmse)\n",
    "        mae_rf.append(mae)\n",
    "\n",
    "        f.write('--- Random Forests ---\\n')\n",
    "        f.write(\"R_squared: %s\\n\" % max(0, r2))\n",
    "        f.write(\"RMSE: %s\\n\" % rmse)\n",
    "        f.write(\"MAE: %s\\n\" % mae)\n",
    "        f.write('\\n')\n",
    "\n",
    "        # LSTM 3-Layer RNN\n",
    "        test_x_val = utils.standardize(test_x).fillna(0).values\n",
    "        test_x_val = test_x_val.reshape((test_x_val.shape[0], 1, test_x_val.shape[1]))\n",
    "        lstm = lstm_rnn(train_x, train_y, test_x, test_y, False)\n",
    "        r2, rmse, mae = utils.eval_results(test_y, lstm.predict(test_x_val).flatten(),\n",
    "                                           False)\n",
    "        # LSTM metrics\n",
    "        r2_lstm.append(max(0, r2))\n",
    "        rmse_lstm.append(rmse)\n",
    "        mae_lstm.append(mae)\n",
    "\n",
    "        f.write('--- LSTM RNN ---\\n')\n",
    "        f.write(\"R_squared: %s\\n\" % max(0, r2))\n",
    "        f.write(\"RMSE: %s\\n\" % rmse)\n",
    "        f.write(\"MAE: %s\\n\" % mae)\n",
    "        f.write('\\n')\n",
    "\n",
    "        # LSTM 1-Layer RNN\n",
    "        lstm_one = one_lstm_rnn(train_x, train_y, test_x, test_y, False)\n",
    "        r2, rmse, mae = utils.eval_results(test_y,\n",
    "                                           lstm_one.predict(test_x_val).flatten(),\n",
    "                                           False)\n",
    "        # LSTM metrics\n",
    "        r2_one_lstm.append(max(0, r2))\n",
    "        rmse_one_lstm.append(rmse)\n",
    "        mae_one_lstm.append(mae)\n",
    "\n",
    "        f.write('--- 1-LSTM RNN ---\\n')\n",
    "        f.write(\"R_squared: %s\\n\" % max(0, r2))\n",
    "        f.write(\"RMSE: %s\\n\" % rmse)\n",
    "        f.write(\"MAE: %s\\n\" % mae)\n",
    "        f.write('\\n')\n",
    "\n",
    "    f.close()\n",
    "    print('---- Elastic-Net Results ----')\n",
    "    utils.average_metrics(r2_elastic, rmse_elastic, mae_elastic)\n",
    "    print('---------------------------------')\n",
    "    print('---- Linear SVM Results ----')\n",
    "    utils.average_metrics(r2_svm, rmse_svm, mae_svm)\n",
    "    print('---------------------------------')\n",
    "    print('---- XGBoost Results ----')\n",
    "    utils.average_metrics(r2_xgb, rmse_xgb, mae_xgb)\n",
    "    print('---------------------------------')\n",
    "    print('---- Random Forest Results ----')\n",
    "    utils.average_metrics(r2_rf, rmse_rf, mae_rf)\n",
    "    print('---------------------------------')\n",
    "    print('---- LSTM Results ----')\n",
    "    utils.average_metrics(r2_lstm, rmse_lstm, mae_lstm)\n",
    "    print('---------------------------------')\n",
    "    print('---- 1-LSTM Results ----')\n",
    "    utils.average_metrics(r2_one_lstm, rmse_one_lstm, mae_one_lstm)\n",
    "    print('---------------------------------')\n",
    "\n",
    "    print('Included patient list:')\n",
    "    print(patient_ids)\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "evaluate_models(train_df, test_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 Evaluating Performance on Entire Dataset (COVID-19 Data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Elastic-Net Results ----\n",
      "Average MAPE: 0.2773520850484139\n",
      "Average RMSE: 0.5623459886076233\n",
      "Average MAE: 0.442329337082762\n",
      "---------------------------------\n",
      "---- Linear SVM Results ----\n",
      "Average MAPE: 0.3036859118100445\n",
      "Average RMSE: 0.7016649878789067\n",
      "Average MAE: 0.5266385901105978\n",
      "---------------------------------\n",
      "---- XGBoost Results ----\n",
      "Average MAPE: 0.24140934098963185\n",
      "Average RMSE: 0.5895927251223831\n",
      "Average MAE: 0.4222593774688022\n",
      "---------------------------------\n",
      "---- Random Forest Results ----\n",
      "Average MAPE: 0.26192897976559715\n",
      "Average RMSE: 0.555708339183514\n",
      "Average MAE: 0.4178085057617078\n",
      "---------------------------------\n",
      "---- LSTM Results ----\n",
      "Average MAPE: 0.4156159113478844\n",
      "Average RMSE: 1.099390933449778\n",
      "Average MAE: 0.9290159608506713\n",
      "---------------------------------\n",
      "---- 1-LSTM Results ----\n",
      "Average MAPE: 0.5264301016042928\n",
      "Average RMSE: 1.2904840615353317\n",
      "Average MAE: 1.1289694471717884\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def evaluate_models(covid_train_x, covid_test_x, covid_train_y, covid_test_y):\n",
    "    mape_elastic, mape_svm, mape_one_lstm, mape_xgb, mape_rf, mape_lstm, mape_mtgnn = ([] for _ in range(7))\n",
    "    rmse_elastic, rmse_svm, rmse_one_lstm, rmse_xgb, rmse_rf, rmse_lstm, rmse_mtgnn = ([] for _ in range(7))\n",
    "    mae_elastic, mae_svm, mae_one_lstm, mae_xgb, mae_rf, mae_lstm, mae_mtgnn = ([] for _ in range(7))\n",
    "\n",
    "    f = open(\"output_idiographic_c.txt\", \"a\")\n",
    "    f.write('- - - PER INDIVIDUAL RESULTS - - -\\n')\n",
    "\n",
    "    for z in range(len(covid_train_x_list)):\n",
    "        # Build and evaluate a model for every single patient\n",
    "\n",
    "        # Elastic-Net (baseline)\n",
    "        elastic = elastic_net(covid_train_x[z], covid_train_y[z], covid_test_x[z], covid_test_y[z], False)\n",
    "        mape, rmse, mae = utils.eval_results_covid(covid_test_y_list[z], elastic.predict(utils.standardize(covid_test_x_list[z]).fillna(0)), False)\n",
    "\n",
    "        # Elastic-Net metrics\n",
    "        mape_elastic.append(mape)\n",
    "        rmse_elastic.append(rmse)\n",
    "        mae_elastic.append(mae)\n",
    "\n",
    "        f.write(\"Patient ID: %s\\n\" % z)\n",
    "        f.write('\\n')\n",
    "        f.write('--- Elastic-Net ---\\n')\n",
    "        f.write(\"MAPE: %s\\n\" % mape)\n",
    "        f.write(\"RMSE: %s\\n\" % rmse)\n",
    "        f.write(\"MAE: %s\\n\" % mae)\n",
    "        f.write('\\n')\n",
    "\n",
    "        # Linear-SVM\n",
    "\n",
    "        params = [\n",
    "            {'C': np.arange(0.1, 2, 0.1),\n",
    "             'epsilon': np.arange(0, 0.5, 0.1),\n",
    "             'loss': ['epsilon_insensitive'],\n",
    "             'fit_intercept': [True],\n",
    "             'max_iter': [10000]}]\n",
    "\n",
    "        svm = linear_svm(covid_train_x[z], covid_train_y[z], covid_test_x[z], covid_test_y[z], False, params)\n",
    "        mape, rmse, mae = utils.eval_results_covid(covid_test_y_list[z], svm.predict(utils.standardize(covid_test_x_list[z]).fillna(0)), False)\n",
    "        # Linear-SVM metrics\n",
    "        mape_svm.append(mape)\n",
    "        rmse_svm.append(rmse)\n",
    "        mae_svm.append(mae)\n",
    "\n",
    "        f.write('--- Linear-SVM ---\\n')\n",
    "        f.write(\"MAPE: %s\\n\" % mape)\n",
    "        f.write(\"RMSE: %s\\n\" % rmse)\n",
    "        f.write(\"MAE: %s\\n\" % mae)\n",
    "        f.write('\\n')\n",
    "\n",
    "        # XGBoost Regression\n",
    "        xgb_covid = xgboost_reg(covid_train_x[z], covid_train_y[z], covid_test_x[z], covid_test_y[z], False)\n",
    "        mape, rmse, mae = utils.eval_results_covid(covid_test_y_list[z], xgb_covid.predict(covid_test_x_list[z]), False)\n",
    "        # XGBoost metrics\n",
    "        mape_xgb.append(mape)\n",
    "        rmse_xgb.append(rmse)\n",
    "        mae_xgb.append(mae)\n",
    "\n",
    "        f.write('--- XGBoost ---\\n')\n",
    "        f.write(\"MAPE: %s\\n\" % mape)\n",
    "        f.write(\"RMSE: %s\\n\" % rmse)\n",
    "        f.write(\"MAE: %s\\n\" % mae)\n",
    "        f.write('\\n')\n",
    "\n",
    "        # RF\n",
    "        rf_covid = random_forests(covid_train_x[z], covid_train_y[z], covid_test_x[z], covid_test_y[z], False)\n",
    "        mape, rmse, mae = utils.eval_results_covid(covid_test_y_list[z], rf_covid.predict(covid_test_x_list[z]), False)\n",
    "        # RF metrics\n",
    "        mape_rf.append(mape)\n",
    "        rmse_rf.append(rmse)\n",
    "        mae_rf.append(mae)\n",
    "\n",
    "        f.write('--- Random Forests ---\\n')\n",
    "        f.write(\"MAPE: %s\\n\" % mape)\n",
    "        f.write(\"RMSE: %s\\n\" % rmse)\n",
    "        f.write(\"MAE: %s\\n\" % mae)\n",
    "        f.write('\\n')\n",
    "\n",
    "        # LSTM 3-Layer RNN\n",
    "        test_x_val = utils.standardize(covid_test_x[z]).fillna(0).values\n",
    "        test_x_val = test_x_val.reshape((test_x_val.shape[0], 1, test_x_val.shape[1]))\n",
    "        lstm_covid = lstm_rnn(covid_train_x[z], covid_train_y[z], covid_test_x[z], covid_test_y[z], False)\n",
    "        mape, rmse, mae = utils.eval_results_covid(covid_test_y_list[z],\n",
    "                                                   lstm_covid.predict(test_x_val).flatten(),\n",
    "                                                   False)\n",
    "        # LSTM metrics\n",
    "        mape_lstm.append(mape)\n",
    "        rmse_lstm.append(rmse)\n",
    "        mae_lstm.append(mae)\n",
    "\n",
    "        f.write('--- LSTM RNN ---\\n')\n",
    "        f.write(\"MAPE: %s\\n\" % mape)\n",
    "        f.write(\"RMSE: %s\\n\" % rmse)\n",
    "        f.write(\"MAE: %s\\n\" % mae)\n",
    "        f.write('\\n')\n",
    "\n",
    "        # LSTM 1-Layer RNN\n",
    "        lstm1_covid = one_lstm_rnn(covid_train_x[z], covid_train_y[z], covid_test_x[z], covid_test_y[z], False)\n",
    "        mape, rmse, mae = utils.eval_results_covid(covid_test_y_list[z],\n",
    "                                                   lstm1_covid.predict(\n",
    "                                                       test_x_val).flatten(),\n",
    "                                                   False)\n",
    "        # LSTM metrics\n",
    "        mape_one_lstm.append(mape)\n",
    "        rmse_one_lstm.append(rmse)\n",
    "        mae_one_lstm.append(mae)\n",
    "\n",
    "        f.write('--- 1-LSTM RNN ---\\n')\n",
    "        f.write(\"MAPE: %s\\n\" % mape)\n",
    "        f.write(\"RMSE: %s\\n\" % rmse)\n",
    "        f.write(\"MAE: %s\\n\" % mae)\n",
    "        f.write('\\n')\n",
    "\n",
    "    f.close()\n",
    "    print('---- Elastic-Net Results ----')\n",
    "    utils.average_metrics_covid(mape_elastic, rmse_elastic, mae_elastic)\n",
    "    print('---------------------------------')\n",
    "    print('---- Linear SVM Results ----')\n",
    "    utils.average_metrics_covid(mape_svm, rmse_svm, mae_svm)\n",
    "    print('---------------------------------')\n",
    "    print('---- XGBoost Results ----')\n",
    "    utils.average_metrics_covid(mape_xgb, rmse_xgb, mae_xgb)\n",
    "    print('---------------------------------')\n",
    "    print('---- Random Forest Results ----')\n",
    "    utils.average_metrics_covid(mape_rf, rmse_rf, mae_rf)\n",
    "    print('---------------------------------')\n",
    "    print('---- LSTM Results ----')\n",
    "    utils.average_metrics_covid(mape_lstm, rmse_lstm, mae_lstm)\n",
    "    print('---------------------------------')\n",
    "    print('---- 1-LSTM Results ----')\n",
    "    utils.average_metrics_covid(mape_one_lstm, rmse_one_lstm, mae_one_lstm)\n",
    "    print('---------------------------------')\n",
    "\n",
    "\n",
    "evaluate_models(covid_train_x_list, covid_test_x_list, covid_train_y_list, covid_test_y_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Nomothethic Approach In separate notebook"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1-step Forecasting with linear and non-linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "import load_data\n",
    "\n",
    "# Plot settings\n",
    "plt.rcParams['figure.figsize'] = (16, 8)\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "sns.set()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "outputs": [
    {
     "data": {
      "text/plain": "    Unnamed: 0  ID               start          finish  drinks  comfortable  \\\n0            1   1 2018-02-06 16:20:00  2/6/2018 16:22       3     7.382609   \n31           2   1 2018-02-06 18:54:00  2/6/2018 18:58       0    14.382609   \n1            3   1 2018-02-06 20:08:00  2/6/2018 20:22       0    15.382609   \n2            4   1 2018-02-06 22:29:00  2/6/2018 22:46       0    21.382609   \n36           5   1 2018-02-07 10:52:00  2/7/2018 11:23       0   -11.617391   \n\n     stressed       down       calm   pressure  ...    cosT.1    sinT.1  \\\n0   -9.817391  10.843478 -37.791304   6.173913  ...  1.000000  0.000000   \n31  47.182609   7.843478   7.208696  10.173913  ...  0.892979  0.450098   \n1   12.182609  10.843478  20.208696  18.173913  ...  0.418660  0.908143   \n2   -5.817391  -2.156522   8.208696   5.173913  ...  0.108867  0.994056   \n36   5.182609   0.843478 -24.791304  -4.826087  ...  0.043619 -0.999048   \n\n     cos2T.1   sin2T.1    cosW.1    sinW.1  dayvar.1  beepvar.1  filter.1  \\\n0   1.000000  0.000000  1.000000  0.000000         1          4         0   \n31  0.594823  0.803857  0.997777  0.066647         1          5         0   \n1  -0.649448  0.760406  0.986795  0.161973         1          6         0   \n2  -0.976296  0.216440  0.978277  0.207302         1          7         0   \n36 -0.996195 -0.087156  0.777930  0.628351         2          1         0   \n\n    consec.1  \n0          1  \n31         2  \n1          3  \n2          4  \n36         7  \n\n[5 rows x 116 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>ID</th>\n      <th>start</th>\n      <th>finish</th>\n      <th>drinks</th>\n      <th>comfortable</th>\n      <th>stressed</th>\n      <th>down</th>\n      <th>calm</th>\n      <th>pressure</th>\n      <th>...</th>\n      <th>cosT.1</th>\n      <th>sinT.1</th>\n      <th>cos2T.1</th>\n      <th>sin2T.1</th>\n      <th>cosW.1</th>\n      <th>sinW.1</th>\n      <th>dayvar.1</th>\n      <th>beepvar.1</th>\n      <th>filter.1</th>\n      <th>consec.1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>2018-02-06 16:20:00</td>\n      <td>2/6/2018 16:22</td>\n      <td>3</td>\n      <td>7.382609</td>\n      <td>-9.817391</td>\n      <td>10.843478</td>\n      <td>-37.791304</td>\n      <td>6.173913</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>2</td>\n      <td>1</td>\n      <td>2018-02-06 18:54:00</td>\n      <td>2/6/2018 18:58</td>\n      <td>0</td>\n      <td>14.382609</td>\n      <td>47.182609</td>\n      <td>7.843478</td>\n      <td>7.208696</td>\n      <td>10.173913</td>\n      <td>...</td>\n      <td>0.892979</td>\n      <td>0.450098</td>\n      <td>0.594823</td>\n      <td>0.803857</td>\n      <td>0.997777</td>\n      <td>0.066647</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>1</td>\n      <td>2018-02-06 20:08:00</td>\n      <td>2/6/2018 20:22</td>\n      <td>0</td>\n      <td>15.382609</td>\n      <td>12.182609</td>\n      <td>10.843478</td>\n      <td>20.208696</td>\n      <td>18.173913</td>\n      <td>...</td>\n      <td>0.418660</td>\n      <td>0.908143</td>\n      <td>-0.649448</td>\n      <td>0.760406</td>\n      <td>0.986795</td>\n      <td>0.161973</td>\n      <td>1</td>\n      <td>6</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>1</td>\n      <td>2018-02-06 22:29:00</td>\n      <td>2/6/2018 22:46</td>\n      <td>0</td>\n      <td>21.382609</td>\n      <td>-5.817391</td>\n      <td>-2.156522</td>\n      <td>8.208696</td>\n      <td>5.173913</td>\n      <td>...</td>\n      <td>0.108867</td>\n      <td>0.994056</td>\n      <td>-0.976296</td>\n      <td>0.216440</td>\n      <td>0.978277</td>\n      <td>0.207302</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>5</td>\n      <td>1</td>\n      <td>2018-02-07 10:52:00</td>\n      <td>2/7/2018 11:23</td>\n      <td>0</td>\n      <td>-11.617391</td>\n      <td>5.182609</td>\n      <td>0.843478</td>\n      <td>-24.791304</td>\n      <td>-4.826087</td>\n      <td>...</td>\n      <td>0.043619</td>\n      <td>-0.999048</td>\n      <td>-0.996195</td>\n      <td>-0.087156</td>\n      <td>0.777930</td>\n      <td>0.628351</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 116 columns</p>\n</div>"
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df, data_raw_list = load_data.load_alcohol()\n",
    "\n",
    "combined_data = []\n",
    "\n",
    "for i in range(len(train_df)):\n",
    "    train = train_df[i]\n",
    "    test = test_df[i]\n",
    "    # Combine both train and test sets since the initial split was 50/50\n",
    "    combined = pd.concat([train, test])\n",
    "    # Sort by date\n",
    "    combined['start'] = pd.to_datetime(combined['start'])\n",
    "    combined = combined.sort_values(by='start')\n",
    "    combined_data.append(combined)\n",
    "\n",
    "combined_data[0].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "outputs": [
    {
     "data": {
      "text/plain": "                start          finish  drinks  comfortable  stressed  down  \\\n1 2018-02-06 16:20:00  2/6/2018 16:22     3.0         81.0      12.0  18.0   \n2 2018-02-06 18:54:00  2/6/2018 18:58     0.0         88.0      69.0  15.0   \n3 2018-02-06 20:08:00  2/6/2018 20:22     0.0         89.0      34.0  18.0   \n4 2018-02-06 22:29:00  2/6/2018 22:46     0.0         95.0      16.0   5.0   \n6 2018-02-07 10:52:00  2/7/2018 11:23     0.0         62.0      27.0   8.0   \n\n   calm  pressure  enthusiastic  happy  ...  impulsive_1  pos_expect_1  \\\n1  26.0      11.0          31.0   56.0  ...          0.0           0.0   \n2  71.0      15.0          83.0   91.0  ...          8.0          14.0   \n3  84.0      23.0          92.0   76.0  ...         15.0          56.0   \n4  72.0      10.0          25.0   66.0  ...         17.0          15.0   \n6  39.0       0.0          66.0   58.0  ...          3.0           0.0   \n\n   peer_percent_1  want_drink_1  delay_grat_1  angry_1  drink_predict_1  \\\n1            17.0           5.0           2.0      9.0              NaN   \n2            55.0          14.0          32.0     15.0              6.0   \n3            78.0          61.0          48.0     14.0              NaN   \n4            73.0          14.0          72.0     16.0              NaN   \n6             4.0           0.0          78.0      7.0              0.0   \n\n   restless_sleep_1  difficulty_sleep_1  hours_sleep_1  \n1               NaN                 NaN            NaN  \n2               7.0                 8.0            7.0  \n3               NaN                 NaN            NaN  \n4               NaN                 NaN            NaN  \n6               5.0                18.0            7.0  \n\n[5 rows x 44 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>start</th>\n      <th>finish</th>\n      <th>drinks</th>\n      <th>comfortable</th>\n      <th>stressed</th>\n      <th>down</th>\n      <th>calm</th>\n      <th>pressure</th>\n      <th>enthusiastic</th>\n      <th>happy</th>\n      <th>...</th>\n      <th>impulsive_1</th>\n      <th>pos_expect_1</th>\n      <th>peer_percent_1</th>\n      <th>want_drink_1</th>\n      <th>delay_grat_1</th>\n      <th>angry_1</th>\n      <th>drink_predict_1</th>\n      <th>restless_sleep_1</th>\n      <th>difficulty_sleep_1</th>\n      <th>hours_sleep_1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>2018-02-06 16:20:00</td>\n      <td>2/6/2018 16:22</td>\n      <td>3.0</td>\n      <td>81.0</td>\n      <td>12.0</td>\n      <td>18.0</td>\n      <td>26.0</td>\n      <td>11.0</td>\n      <td>31.0</td>\n      <td>56.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>17.0</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-02-06 18:54:00</td>\n      <td>2/6/2018 18:58</td>\n      <td>0.0</td>\n      <td>88.0</td>\n      <td>69.0</td>\n      <td>15.0</td>\n      <td>71.0</td>\n      <td>15.0</td>\n      <td>83.0</td>\n      <td>91.0</td>\n      <td>...</td>\n      <td>8.0</td>\n      <td>14.0</td>\n      <td>55.0</td>\n      <td>14.0</td>\n      <td>32.0</td>\n      <td>15.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>8.0</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-02-06 20:08:00</td>\n      <td>2/6/2018 20:22</td>\n      <td>0.0</td>\n      <td>89.0</td>\n      <td>34.0</td>\n      <td>18.0</td>\n      <td>84.0</td>\n      <td>23.0</td>\n      <td>92.0</td>\n      <td>76.0</td>\n      <td>...</td>\n      <td>15.0</td>\n      <td>56.0</td>\n      <td>78.0</td>\n      <td>61.0</td>\n      <td>48.0</td>\n      <td>14.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-02-06 22:29:00</td>\n      <td>2/6/2018 22:46</td>\n      <td>0.0</td>\n      <td>95.0</td>\n      <td>16.0</td>\n      <td>5.0</td>\n      <td>72.0</td>\n      <td>10.0</td>\n      <td>25.0</td>\n      <td>66.0</td>\n      <td>...</td>\n      <td>17.0</td>\n      <td>15.0</td>\n      <td>73.0</td>\n      <td>14.0</td>\n      <td>72.0</td>\n      <td>16.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2018-02-07 10:52:00</td>\n      <td>2/7/2018 11:23</td>\n      <td>0.0</td>\n      <td>62.0</td>\n      <td>27.0</td>\n      <td>8.0</td>\n      <td>39.0</td>\n      <td>0.0</td>\n      <td>66.0</td>\n      <td>58.0</td>\n      <td>...</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>78.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>18.0</td>\n      <td>7.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 44 columns</p>\n</div>"
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading in data and pre-processing\n",
    "train_df, test_df, data_raw_list = load_data.load_alcohol()\n",
    "\n",
    "for i in range(len(data_raw_list)):\n",
    "    data_raw_list[i] = load_data.prepare_data_alcohol(data_raw_list[i])\n",
    "    data_raw_list[i]['start'] = pd.to_datetime(data_raw_list[i]['start'])\n",
    "    lag_one = data_raw_list[i].shift()\n",
    "    lag_one = lag_one.add_suffix('_1')\n",
    "    data_raw_list[i] = pd.concat([data_raw_list[i], lag_one], axis=1)\n",
    "    data_raw_list[i] = data_raw_list[i][data_raw_list[i]['finish'].notna()]\n",
    "    data_raw_list[i] = data_raw_list[i][data_raw_list[i]['finish_1'].notna()]\n",
    "    data_raw_list[i] = data_raw_list[i][data_raw_list[i]['drinks'].notna()]\n",
    "    data_raw_list[i] = data_raw_list[i][data_raw_list[i]['drinks_1'].notna()]\n",
    "    data_raw_list[i] = data_raw_list[i][~(data_raw_list[i]['start'].dt.day != data_raw_list[i]['start_1'].dt.day)]\n",
    "\n",
    "data_raw_list[0].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Idiographic Models Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "outputs": [],
   "source": [
    "# Predict craving\n",
    "\n",
    "# Make own splits\n",
    "def prepare_data_own(idx, combined_list, random_state):\n",
    "    #print('Patient ID:', combined_list[idx].iloc[0]['ID'])\n",
    "    X = combined_list[idx].drop(combined_list[idx].columns[range(0, 24)], axis=1).fillna(0)\n",
    "    y = combined_list[idx]['craving']\n",
    "\n",
    "    return train_test_split(X, y, test_size=0.3, random_state=random_state)\n",
    "\n",
    "\n",
    "def prepare_data(idx, train_list, test_list):\n",
    "    print('Patient ID:', train_list[idx]['ID'][0])\n",
    "\n",
    "    X_train = train_list[idx].drop(train_list[idx].columns[range(0, 61)], axis=1).fillna(0)\n",
    "    y_train = train_list[idx]['craving']\n",
    "    X_test = test_list[idx].drop(test_list[idx].columns[range(0, 61)], axis=1).fillna(0)\n",
    "    y_test = test_list[idx]['craving']\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def standardize(data):\n",
    "    local = data.copy()\n",
    "    for col in local.columns:\n",
    "        local[col] = (local[col] - local[col].mean()) / np.std(local[col])\n",
    "    return local\n",
    "\n",
    "\n",
    "def eval_results(actual, predicted, show):\n",
    "    r2 = metrics.r2_score(actual, predicted)\n",
    "    rmse = metrics.mean_squared_error(actual, predicted, squared=False)\n",
    "    mape = metrics.mean_absolute_percentage_error(actual, predicted)\n",
    "\n",
    "    if show:\n",
    "        print('R_squared:', r2)\n",
    "        print('MAPE:', mape)\n",
    "        print('RMSE:', rmse)\n",
    "        print('MAE:', metrics.mean_absolute_error(actual, predicted))\n",
    "        print('CORR:', np.corrcoef(predicted, actual)[0, 1])\n",
    "\n",
    "    return r2, rmse, mape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1 Lasso Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: 2\n",
      "R_squared: 0.2336748819426997\n",
      "MAPE: 0.8602057458801604\n",
      "RMSE: 21.500863785473992\n",
      "MAE: 16.922922828939296\n",
      "CORR: 0.5125876082907408\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.2336748819426997, 21.500863785473992, 0.8602057458801604)"
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = prepare_data(1, train_list=train_df, test_list=test_df)\n",
    "\n",
    "\n",
    "def lasso_reg(train_x, train_y, test_x, test_y, vis):\n",
    "    X_train_loc = standardize(train_x).fillna(0)\n",
    "    X_test_loc = standardize(test_x).fillna(0)\n",
    "\n",
    "    alphas = np.arange(0.01, 20, 0.05)\n",
    "    lasso = lm.LassoCV(alphas=alphas, cv=5, max_iter=100000, fit_intercept=True)\n",
    "    lasso.fit(X_train_loc, train_y)\n",
    "    y_predicted_test = lasso.predict(X_test_loc)\n",
    "\n",
    "    # print('--- Lasso Regression Results ---')\n",
    "    # print()\n",
    "    r2, rmse, mape = eval_results(actual=test_y, predicted=y_predicted_test, show=vis)\n",
    "\n",
    "    return r2, rmse, mape\n",
    "\n",
    "\n",
    "lasso_reg(X_train, y_train, X_test, y_test, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 Elastic-Net Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_squared: 0.3105248292112299\n",
      "MAPE: 0.868046768759073\n",
      "RMSE: 20.394294809977133\n",
      "MAE: 16.71060148405697\n",
      "CORR: 0.5610027960444378\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.3105248292112299, 20.394294809977133, 0.868046768759073)"
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def elastic_net(train_x, train_y, test_x, test_y, vis):\n",
    "    X_train_loc = standardize(train_x).fillna(0)\n",
    "    X_test_loc = standardize(test_x).fillna(0)\n",
    "\n",
    "    l1_ratios = np.arange(0.01, 0.6, 0.05)\n",
    "    elastic_reg = lm.ElasticNetCV(alphas=np.arange(0.01, 20, 0.05), l1_ratio=l1_ratios, cv=5, max_iter=100000,\n",
    "                                  fit_intercept=True)\n",
    "    elastic_reg.fit(X_train_loc, train_y)\n",
    "    y_predicted_test = elastic_reg.predict(X_test_loc)\n",
    "\n",
    "    # print('--- Elastic-Net Results ---')\n",
    "    # print()\n",
    "    r2, rmse, mape = eval_results(actual=test_y, predicted=y_predicted_test, show=vis)\n",
    "    return r2, rmse, mape\n",
    "\n",
    "\n",
    "elastic_net(X_train, y_train, X_test, y_test, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3 Linear SVM Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_squared: 0.3356438834226828\n",
      "MAPE: 0.8317165121227911\n",
      "RMSE: 20.01934418628923\n",
      "MAE: 16.08854279048022\n",
      "CORR: 0.5836003576596637\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.3356438834226828, 20.01934418628923, 0.8317165121227911)"
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def linear_svm(train_x, train_y, test_x, test_y, vis):\n",
    "    X_train_loc = standardize(train_x).fillna(0)\n",
    "    X_test_loc = standardize(test_x).fillna(0)\n",
    "\n",
    "    params = [\n",
    "        {'C': np.arange(0.1, 4, 0.1),\n",
    "         'epsilon': np.arange(6, 7, 0.1),\n",
    "         'loss': ['epsilon_insensitive'],\n",
    "         'fit_intercept': [True],\n",
    "         'max_iter': [10000]}]\n",
    "\n",
    "    clf = GridSearchCV(estimator=LinearSVR(), param_grid=params, scoring='r2', cv=5)\n",
    "    clf.fit(X_train_loc, train_y)\n",
    "    # best_params = clf.best_params_\n",
    "    # print(best_params)\n",
    "    y_predicted_test = clf.predict(X_test_loc)\n",
    "\n",
    "    # print('--- Linear-SVM Results ---')\n",
    "    # print()\n",
    "    r2, rmse, mape = eval_results(actual=test_y, predicted=y_predicted_test, show=vis)\n",
    "    return r2, rmse, mape\n",
    "\n",
    "\n",
    "linear_svm(X_train, y_train, X_test, y_test, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.4 K-NN Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_squared: 0.14247416686246706\n",
      "MAPE: 1.0065771554001917\n",
      "RMSE: 22.744321386225067\n",
      "MAE: 17.094135426343126\n",
      "CORR: 0.49368573617049394\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.14247416686246706, 22.744321386225067, 1.0065771554001917)"
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def knn_reg(train_x, train_y, test_x, test_y, vis):\n",
    "    params = [\n",
    "        {'weights': ['uniform', 'distance'],\n",
    "         'n_neighbors': np.arange(2, 20, 1)}]\n",
    "\n",
    "    clf = GridSearchCV(estimator=KNeighborsRegressor(), param_grid=params, scoring='neg_mean_squared_error', cv=2)\n",
    "    clf.fit(train_x, train_y)\n",
    "    # best_params = clf.best_params_\n",
    "    # print(best_params)\n",
    "\n",
    "    y_predicted_test = clf.predict(test_x)\n",
    "\n",
    "    # print('--- kNN Regression Results ---')\n",
    "    # print()\n",
    "    r2, rmse, mape = eval_results(actual=test_y, predicted=y_predicted_test, show=vis)\n",
    "    return r2, rmse, mape\n",
    "\n",
    "\n",
    "knn_reg(X_train, y_train, X_test, y_test, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.5 Symbolic Regressions (Genetic Algorithm basically)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    12.85          11005.5        3          20.6789              N/A     13.55s\n",
      "   1     8.61          94.3492        5          18.0261              N/A     11.08s\n",
      "   2     8.81          40.6437        3          17.9199              N/A     15.94s\n",
      "   3     7.64          31.6061        3          17.9199              N/A     11.54s\n",
      "   4     6.21          31.5061        7          16.4142              N/A      9.11s\n",
      "   5     6.94          35.5869        5          16.1092              N/A      7.76s\n",
      "   6    10.47          36.8222       12          15.3856              N/A      5.46s\n",
      "   7    13.77          61.7009       13          15.0662              N/A      4.00s\n",
      "   8    15.28          46.9933       13          15.0662              N/A      2.28s\n",
      "   9    15.89          34.4922       40          14.9665              N/A      0.00s\n",
      "R_squared: 0.0022095356145428457\n",
      "MAPE: 0.8716965965602719\n",
      "RMSE: 24.53403903990671\n",
      "MAE: 18.071008919684274\n",
      "CORR: 0.45855624280967616\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.0022095356145428457, 24.53403903990671, 0.8716965965602719)"
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gplearn.genetic import SymbolicRegressor\n",
    "\n",
    "function_set = ['add', 'sub', 'mul', 'div', 'sin', 'log']\n",
    "model = SymbolicRegressor(population_size=3000, tournament_size=5,\n",
    "                          generations=10, stopping_criteria=0.1,\n",
    "                          function_set=function_set, metric='rmse',\n",
    "                          p_crossover=0.65, p_subtree_mutation=0.15,\n",
    "                          p_hoist_mutation=0.05, p_point_mutation=0.1,\n",
    "                          verbose=1, random_state=None, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "eval_results(actual=y_test, predicted=predicted, show=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.6 XGBoost Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_squared: 0.24420213612928443\n",
      "MAPE: 0.7930023802589711\n",
      "RMSE: 21.352670947844835\n",
      "MAE: 16.99780234873153\n",
      "CORR: 0.5215126732652979\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.24420213612928443, 21.352670947844835, 0.7930023802589711)"
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def xgboost_reg(train_x, train_y, test_x, test_y, vis):\n",
    "    # Very simple models work better here, since there are few datapoints\n",
    "    params = [\n",
    "        {'objective': ['reg:squarederror'],\n",
    "         'n_estimators': np.arange(1, 7, 1),\n",
    "         'eval_metric': ['rmse'],\n",
    "         'max_depth': np.arange(1, 5, 1)}]\n",
    "\n",
    "    reg_xgb = GridSearchCV(xgb.XGBRegressor(), params, n_jobs=5, cv=5, scoring='r2')\n",
    "    reg_xgb.fit(train_x, train_y)\n",
    "\n",
    "    y_predicted_test = reg_xgb.predict(test_x)\n",
    "\n",
    "    # print('--- XGBoost Regression Results ---')\n",
    "    # print()\n",
    "    r2, rmse, mape = eval_results(actual=test_y, predicted=y_predicted_test, show=vis)\n",
    "    return r2, rmse, mape\n",
    "\n",
    "\n",
    "xgboost_reg(X_train, y_train, X_test, y_test, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.7 Random Forests"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_squared: 0.285144301605625\n",
      "MAPE: 0.8360945732237236\n",
      "RMSE: 20.766273480952577\n",
      "MAE: 17.195510204081636\n",
      "CORR: 0.5455414619322225\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.285144301605625, 20.766273480952577, 0.8360945732237236)"
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "def random_forests(train_x, train_y, test_x, test_y, vis):\n",
    "    grid = [\n",
    "        {'n_estimators': [50, 70, 100],\n",
    "         'max_features': ['auto', 'sqrt'],\n",
    "         'max_depth': [5, 10, 15, 20],\n",
    "         'min_samples_split': [2, 4, 6],\n",
    "         'min_samples_leaf': [1],\n",
    "         'bootstrap': [True]}]\n",
    "\n",
    "    rf = GridSearchCV(RandomForestRegressor(), param_grid=grid, cv=5, scoring='r2')\n",
    "    rf.fit(train_x, train_y)\n",
    "    y_predicted_test = rf.predict(test_x)\n",
    "    # print(rf.best_params_)\n",
    "\n",
    "    r2, rmse, mape = eval_results(actual=test_y, predicted=y_predicted_test, show=vis)\n",
    "    return r2, rmse, mape\n",
    "\n",
    "\n",
    "random_forests(X_train, y_train, X_test, y_test, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.8 LSTM RNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_squared: 0.07775874048200226\n",
      "MAPE: 0.8882427120793301\n",
      "RMSE: 23.586942665661006\n",
      "MAE: 20.90448520245254\n",
      "CORR: 0.5333149994152293\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.07775874048200226, 23.586942665661006, 0.8882427120793301)"
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras.layers\n",
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "def lstm_rnn(train_x, train_y, test_x, test_y, vis):\n",
    "    X_train_loc = standardize(train_x).fillna(0)\n",
    "    X_test_loc = standardize(test_x).fillna(0)\n",
    "    train_x_val, train_y_val, test_x_val, test_y_val = X_train_loc.values, train_y.values, X_test_loc.values, test_y.values\n",
    "\n",
    "    train_x_val = train_x_val.reshape((train_x_val.shape[0], 1, train_x_val.shape[1]))\n",
    "    test_x_val = test_x_val.reshape((test_x_val.shape[0], 1, test_x_val.shape[1]))\n",
    "\n",
    "    # print(train_x_val.shape)\n",
    "    # print(test_x_val.shape)\n",
    "\n",
    "    model = Sequential([\n",
    "        keras.layers.LSTM(100, return_sequences=True, input_shape=(train_x_val.shape[1], train_x_val.shape[2])),\n",
    "        keras.layers.Dropout(0.25),\n",
    "        keras.layers.LSTM(units=50, return_sequences=True),\n",
    "        keras.layers.Dropout(0.20),\n",
    "        keras.layers.LSTM(units=10, return_sequences=False),\n",
    "        keras.layers.Dense(units=1, activation='linear'),\n",
    "    ])\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    model.fit(train_x_val, train_y_val, epochs=15, batch_size=4, verbose=0, shuffle=False)\n",
    "\n",
    "    y_predicted_test = model.predict(test_x_val)\n",
    "\n",
    "    r2, rmse, mape = eval_results(actual=test_y, predicted=y_predicted_test.flatten(), show=vis)\n",
    "    return r2, rmse, mape\n",
    "\n",
    "\n",
    "lstm_rnn(X_train, y_train, X_test, y_test, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.9 MTGNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as f\n",
    "from torch_geometric_temporal.nn.recurrent.gconv_gru import GConvGRU\n",
    "\n",
    "\n",
    "class RecurrentGCN(torch.nn.Module):\n",
    "    def __init__(self, node_features, filters):\n",
    "        super(RecurrentGCN, self).__init__()\n",
    "        self.recurrent = GConvGRU(node_features, filters, 2)\n",
    "        self.linear = torch.nn.Linear(filters, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        h = self.recurrent(x, edge_index, edge_weight)\n",
    "        h = f.relu(h)\n",
    "        h = self.linear(h)\n",
    "        return h"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Evaluating Performance on Entire Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: 1\n",
      "Patient ID: 2\n",
      "Patient ID: 3\n",
      "Patient ID: 4\n",
      "Patient ID: 5\n",
      "Patient ID: 6\n",
      "Patient ID: 7\n",
      "Patient ID: 8\n",
      "Patient ID: 9\n",
      "Patient ID: 10\n",
      "Patient ID: 12\n",
      "Patient ID: 14\n",
      "Patient ID: 15\n",
      "Patient ID: 16\n",
      "Patient ID: 17\n",
      "Patient ID: 18\n",
      "Patient ID: 19\n",
      "Patient ID: 20\n",
      "Patient ID: 21\n",
      "Patient ID: 22\n",
      "Patient ID: 23\n",
      "Patient ID: 24\n",
      "Patient ID: 25\n",
      "Patient ID: 26\n",
      "Patient ID: 27\n",
      "Patient ID: 29\n",
      "Patient ID: 30\n",
      "Patient ID: 32\n",
      "---- Lasso Regression Results ----\n",
      "Average R_Squared: 0.1770519351340509\n",
      "Average RMSE: 14.717961396686716\n",
      "Average MAPE: 1.5472097567998122\n",
      "---------------------------------\n",
      "---- Elastic-Net Results ----\n",
      "Average R_Squared: 0.194006559997254\n",
      "Average RMSE: 14.771363649360774\n",
      "Average MAPE: 1.4156218369947697\n",
      "---------------------------------\n",
      "---- Linear SVM Results ----\n",
      "Average R_Squared: 0.1915070799352016\n",
      "Average RMSE: 14.380320413866242\n",
      "Average MAPE: 1.2752770423667938\n",
      "---------------------------------\n",
      "---- kNN Regression Results ----\n",
      "Average R_Squared: 0.11997494708105814\n",
      "Average RMSE: 15.304156621838958\n",
      "Average MAPE: 1.6650125231400603\n",
      "---------------------------------\n",
      "---- XGBoost Results ----\n",
      "Average R_Squared: 0.13531839030497356\n",
      "Average RMSE: 14.959761776431913\n",
      "Average MAPE: 1.2691723175653098\n",
      "---------------------------------\n",
      "---- Random Forest Results ----\n",
      "Average R_Squared: 0.19082360943063223\n",
      "Average RMSE: 14.449283890712403\n",
      "Average MAPE: 1.4744041514705\n",
      "---------------------------------\n",
      "---- LSTM Results ----\n",
      "Average R_Squared: 0.0495158196541574\n",
      "Average RMSE: 15.703646062115192\n",
      "Average MAPE: 1.0773984656569764\n",
      "---------------------------------\n",
      "Included patient list:\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "\n",
    "def average_metrics(r2_list, rmse_list, mape_list):\n",
    "    print('Average R_Squared:', np.mean(r2_list))\n",
    "    print('Average RMSE:', np.mean(rmse_list))\n",
    "    print('Average MAPE:', np.mean(mape_list))\n",
    "\n",
    "\n",
    "def evaluate_models(train_list, test_list):\n",
    "    assert len(train_list) == len(test_list)\n",
    "    r2_lasso, r2_elastic, r2_svm, r2_knn, r2_xgb, r2_rf, r2_lstm, r2_mtgnn = ([] for _ in range(8))\n",
    "    rmse_lasso, rmse_elastic, rmse_svm, rmse_knn, rmse_xgb, rmse_rf, rmse_lstm, rmse_mtgnn = ([] for _ in range(8))\n",
    "    mape_lasso, mape_elastic, mape_svm, mape_knn, mape_xgb, mape_rf, mape_lstm, mape_mtgnn = ([] for _ in range(8))\n",
    "\n",
    "    patient_ids = []\n",
    "\n",
    "    for x in range(len(train_list)):\n",
    "        # Build and evaluate a model for every single patient\n",
    "        train_x, test_x, train_y, test_y = prepare_data(x, train_list=train_list, test_list=test_list)\n",
    "        # Elastic-Net (baseline)\n",
    "        r2, rmse, mape = elastic_net(train_x, train_y, test_x, test_y,\n",
    "                                     False)  # only continue with other models if this one can get a positive r2\n",
    "\n",
    "        # Elastic-Net metrics\n",
    "        patient_ids.append(train_list[x]['ID'][0])\n",
    "        r2_elastic.append(max(0, r2))\n",
    "        rmse_elastic.append(rmse)\n",
    "        mape_elastic.append(mape)\n",
    "\n",
    "        # Lasso Regression\n",
    "        r2, rmse, mape = lasso_reg(train_x, train_y, test_x, test_y, False)\n",
    "        # Lasso metrics\n",
    "        r2_lasso.append(max(0, r2))\n",
    "        rmse_lasso.append(rmse)\n",
    "        mape_lasso.append(mape)\n",
    "\n",
    "        # Linear-SVM\n",
    "        r2, rmse, mape = linear_svm(train_x, train_y, test_x, test_y, False)\n",
    "        # Linear-SVM metrics\n",
    "        r2_svm.append(max(0, r2))\n",
    "        rmse_svm.append(rmse)\n",
    "        mape_svm.append(mape)\n",
    "\n",
    "        # kNN Regression\n",
    "        r2, rmse, mape = knn_reg(train_x, train_y, test_x, test_y, False)\n",
    "        # kNN metrics\n",
    "        r2_knn.append(max(0, r2))\n",
    "        rmse_knn.append(rmse)\n",
    "        mape_knn.append(mape)\n",
    "\n",
    "        # XGBoost Regression\n",
    "        r2, rmse, mape = xgboost_reg(train_x, train_y, test_x, test_y, False)\n",
    "        # XGBoost metrics\n",
    "        r2_xgb.append(max(0, r2))\n",
    "        rmse_xgb.append(rmse)\n",
    "        mape_xgb.append(mape)\n",
    "\n",
    "        # RF\n",
    "        r2, rmse, mape = random_forests(train_x, train_y, test_x, test_y, False)\n",
    "        # RF metrics\n",
    "        r2_rf.append(max(0, r2))\n",
    "        rmse_rf.append(rmse)\n",
    "        mape_rf.append(mape)\n",
    "\n",
    "        # LSTM RNN\n",
    "        r2, rmse, mape = lstm_rnn(train_x, train_y, test_x, test_y, False)\n",
    "        # LSTM metrics\n",
    "        r2_lstm.append(max(0, r2))\n",
    "        rmse_lstm.append(rmse)\n",
    "        mape_lstm.append(mape)\n",
    "\n",
    "    print('---- Lasso Regression Results ----')\n",
    "    average_metrics(r2_lasso, rmse_lasso, mape_lasso)\n",
    "    print('---------------------------------')\n",
    "    print('---- Elastic-Net Results ----')\n",
    "    average_metrics(r2_elastic, rmse_elastic, mape_elastic)\n",
    "    print('---------------------------------')\n",
    "    print('---- Linear SVM Results ----')\n",
    "    average_metrics(r2_svm, rmse_svm, mape_svm)\n",
    "    print('---------------------------------')\n",
    "    print('---- kNN Regression Results ----')\n",
    "    average_metrics(r2_knn, rmse_knn, mape_knn)\n",
    "    print('---------------------------------')\n",
    "    print('---- XGBoost Results ----')\n",
    "    average_metrics(r2_xgb, rmse_xgb, mape_xgb)\n",
    "    print('---------------------------------')\n",
    "    print('---- Random Forest Results ----')\n",
    "    average_metrics(r2_rf, rmse_rf, mape_rf)\n",
    "    print('---------------------------------')\n",
    "    print('---- LSTM Results ----')\n",
    "    average_metrics(r2_lstm, rmse_lstm, mape_lstm)\n",
    "    print('---------------------------------')\n",
    "\n",
    "    print('Included patient list:')\n",
    "    print(patient_ids)\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "evaluate_models(train_df, test_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Nomothetic Models Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### In separate notebook"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1-step Forecasting with linear and non-linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tools.eval_measures import rmse, aic\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "\n",
    "import load_data\n",
    "\n",
    "# Plot settings\n",
    "plt.rcParams['figure.figsize'] = (16, 8)\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "sns.set()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "outputs": [
    {
     "data": {
      "text/plain": "    Unnamed: 0  ID               start          finish  drinks  comfortable  \\\n0            1   1 2018-02-06 16:20:00  2/6/2018 16:22       3     7.382609   \n31           2   1 2018-02-06 18:54:00  2/6/2018 18:58       0    14.382609   \n1            3   1 2018-02-06 20:08:00  2/6/2018 20:22       0    15.382609   \n2            4   1 2018-02-06 22:29:00  2/6/2018 22:46       0    21.382609   \n36           5   1 2018-02-07 10:52:00  2/7/2018 11:23       0   -11.617391   \n\n     stressed       down       calm   pressure  ...    cosT.1    sinT.1  \\\n0   -9.817391  10.843478 -37.791304   6.173913  ...  1.000000  0.000000   \n31  47.182609   7.843478   7.208696  10.173913  ...  0.892979  0.450098   \n1   12.182609  10.843478  20.208696  18.173913  ...  0.418660  0.908143   \n2   -5.817391  -2.156522   8.208696   5.173913  ...  0.108867  0.994056   \n36   5.182609   0.843478 -24.791304  -4.826087  ...  0.043619 -0.999048   \n\n     cos2T.1   sin2T.1    cosW.1    sinW.1  dayvar.1  beepvar.1  filter.1  \\\n0   1.000000  0.000000  1.000000  0.000000         1          4         0   \n31  0.594823  0.803857  0.997777  0.066647         1          5         0   \n1  -0.649448  0.760406  0.986795  0.161973         1          6         0   \n2  -0.976296  0.216440  0.978277  0.207302         1          7         0   \n36 -0.996195 -0.087156  0.777930  0.628351         2          1         0   \n\n    consec.1  \n0          1  \n31         2  \n1          3  \n2          4  \n36         7  \n\n[5 rows x 116 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>ID</th>\n      <th>start</th>\n      <th>finish</th>\n      <th>drinks</th>\n      <th>comfortable</th>\n      <th>stressed</th>\n      <th>down</th>\n      <th>calm</th>\n      <th>pressure</th>\n      <th>...</th>\n      <th>cosT.1</th>\n      <th>sinT.1</th>\n      <th>cos2T.1</th>\n      <th>sin2T.1</th>\n      <th>cosW.1</th>\n      <th>sinW.1</th>\n      <th>dayvar.1</th>\n      <th>beepvar.1</th>\n      <th>filter.1</th>\n      <th>consec.1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>2018-02-06 16:20:00</td>\n      <td>2/6/2018 16:22</td>\n      <td>3</td>\n      <td>7.382609</td>\n      <td>-9.817391</td>\n      <td>10.843478</td>\n      <td>-37.791304</td>\n      <td>6.173913</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>2</td>\n      <td>1</td>\n      <td>2018-02-06 18:54:00</td>\n      <td>2/6/2018 18:58</td>\n      <td>0</td>\n      <td>14.382609</td>\n      <td>47.182609</td>\n      <td>7.843478</td>\n      <td>7.208696</td>\n      <td>10.173913</td>\n      <td>...</td>\n      <td>0.892979</td>\n      <td>0.450098</td>\n      <td>0.594823</td>\n      <td>0.803857</td>\n      <td>0.997777</td>\n      <td>0.066647</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>1</td>\n      <td>2018-02-06 20:08:00</td>\n      <td>2/6/2018 20:22</td>\n      <td>0</td>\n      <td>15.382609</td>\n      <td>12.182609</td>\n      <td>10.843478</td>\n      <td>20.208696</td>\n      <td>18.173913</td>\n      <td>...</td>\n      <td>0.418660</td>\n      <td>0.908143</td>\n      <td>-0.649448</td>\n      <td>0.760406</td>\n      <td>0.986795</td>\n      <td>0.161973</td>\n      <td>1</td>\n      <td>6</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>1</td>\n      <td>2018-02-06 22:29:00</td>\n      <td>2/6/2018 22:46</td>\n      <td>0</td>\n      <td>21.382609</td>\n      <td>-5.817391</td>\n      <td>-2.156522</td>\n      <td>8.208696</td>\n      <td>5.173913</td>\n      <td>...</td>\n      <td>0.108867</td>\n      <td>0.994056</td>\n      <td>-0.976296</td>\n      <td>0.216440</td>\n      <td>0.978277</td>\n      <td>0.207302</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>5</td>\n      <td>1</td>\n      <td>2018-02-07 10:52:00</td>\n      <td>2/7/2018 11:23</td>\n      <td>0</td>\n      <td>-11.617391</td>\n      <td>5.182609</td>\n      <td>0.843478</td>\n      <td>-24.791304</td>\n      <td>-4.826087</td>\n      <td>...</td>\n      <td>0.043619</td>\n      <td>-0.999048</td>\n      <td>-0.996195</td>\n      <td>-0.087156</td>\n      <td>0.777930</td>\n      <td>0.628351</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 116 columns</p>\n</div>"
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df, data_raw_list = load_data.load_alcohol()\n",
    "\n",
    "combined_data = []\n",
    "\n",
    "for i in range(len(train_df)):\n",
    "    train = train_df[i]\n",
    "    test = test_df[i]\n",
    "    # Combine both train and test sets since the initial split was 50/50\n",
    "    combined = pd.concat([train, test])\n",
    "    # Sort by date\n",
    "    combined['start'] = pd.to_datetime(combined['start'])\n",
    "    combined = combined.sort_values(by='start')\n",
    "    combined_data.append(combined)\n",
    "\n",
    "# Dataset with all individual's data\n",
    "global_data = pd.concat(combined_data, ignore_index=True)\n",
    "combined_data[0].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Idiographic Models Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Patient ID: 14\n",
      "Test Patient ID: 14\n"
     ]
    }
   ],
   "source": [
    "# Predict craving\n",
    "\n",
    "# Collect train and test sets as was done in the paper\n",
    "print('Train Patient ID:', train_df[12]['ID'][0])\n",
    "print('Test Patient ID:', test_df[12]['ID'][0])\n",
    "X_train = train_df[12].drop(train_df[12].columns[range(0, 61)], axis=1).fillna(0)\n",
    "y_train = train_df[12]['craving']\n",
    "X_test = test_df[12].drop(test_df[12].columns[range(0, 61)], axis=1).fillna(0)\n",
    "y_test = test_df[12]['craving']\n",
    "\n",
    "\n",
    "def standardize(data):\n",
    "    for col in data.columns:\n",
    "        data[col] = (data[col] - data[col].mean()) / np.std(data[col])\n",
    "    return data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1 Lasso Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_squared: 0.5821437826058486\n",
      "MAPE: 1.17437925717085\n",
      "RMSE: 8.39410535185786\n"
     ]
    }
   ],
   "source": [
    "X_train = standardize(X_train).fillna(0)\n",
    "X_test = standardize(X_test).fillna(0)\n",
    "\n",
    "alphas = np.arange(0.1, 200, .1)\n",
    "lasso_reg = lm.LassoCV(alphas=alphas, cv=5, max_iter=10000)\n",
    "lasso_reg.fit(X_train, y_train)\n",
    "y_predicted_test = lasso_reg.predict(X_test)\n",
    "\n",
    "print('R_squared:', metrics.r2_score(y_test, y_predicted_test))\n",
    "print('MAPE:', metrics.mean_absolute_percentage_error(y_test, y_predicted_test))\n",
    "print('RMSE:', metrics.mean_squared_error(y_test, y_predicted_test, squared=False))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 Elastic-Net Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_squared: 0.6330224747427082\n",
      "MAPE: 0.9195012167791153\n",
      "RMSE: 7.866484932707291\n"
     ]
    }
   ],
   "source": [
    "l1_ratios = np.arange(0.5, 1, 0.05)\n",
    "alphas = np.arange(0.1, 100, .1)\n",
    "elastic_reg = lm.ElasticNetCV(alphas=alphas, cv=5, l1_ratio=l1_ratios, max_iter=10000)\n",
    "elastic_reg.fit(X_train, y_train)\n",
    "\n",
    "y_predicted_test = elastic_reg.predict(X_test)\n",
    "\n",
    "print('R_squared:', metrics.r2_score(y_test, y_predicted_test))\n",
    "print('MAPE:', metrics.mean_absolute_percentage_error(y_test, y_predicted_test))\n",
    "print('RMSE:', metrics.mean_squared_error(y_test, y_predicted_test, squared=False))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3 Linear SVM Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'epsilon': 6.0, 'fit_intercept': False, 'loss': 'epsilon_insensitive', 'max_iter': 10000}\n",
      "R_squared: 0.5662840357157135\n",
      "MAPE: 0.9496389517582751\n",
      "RMSE: 8.551921098644316\n"
     ]
    }
   ],
   "source": [
    "params = [\n",
    "    {'C': np.arange(0.1, 4, 0.1),\n",
    "     'epsilon': np.arange(6, 7, 0.1),\n",
    "     'loss': ['epsilon_insensitive'],\n",
    "     'fit_intercept': [False],\n",
    "     'max_iter': [10000]}]\n",
    "\n",
    "clf = GridSearchCV(estimator=LinearSVR(), param_grid=params, scoring='r2', cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "best_params = clf.best_params_\n",
    "print(best_params)\n",
    "\n",
    "y_predicted_test = clf.predict(X_test)\n",
    "\n",
    "print('R_squared:', metrics.r2_score(y_test, y_predicted_test))\n",
    "print('MAPE:', metrics.mean_absolute_percentage_error(y_test, y_predicted_test))\n",
    "print('RMSE:', metrics.mean_squared_error(y_test, y_predicted_test, squared=False))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.4 K-NN Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 15, 'weights': 'uniform'}\n",
      "R_squared: 0.13873596353952167\n",
      "MAPE: 1.360770936631153\n",
      "RMSE: 12.051167916353508\n"
     ]
    }
   ],
   "source": [
    "X_train = train_df[12].drop(train_df[12].columns[range(0, 61)], axis=1).fillna(0)\n",
    "y_train = train_df[12]['craving']\n",
    "X_test = test_df[12].drop(test_df[12].columns[range(0, 61)], axis=1).fillna(0)\n",
    "y_test = test_df[12]['craving']\n",
    "\n",
    "params = [\n",
    "    {'weights': ['uniform', 'distance'],\n",
    "     'n_neighbors': np.arange(1, 30, 1)}]\n",
    "\n",
    "clf = GridSearchCV(estimator=KNeighborsRegressor(), param_grid=params, scoring='r2', cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "best_params = clf.best_params_\n",
    "print(best_params)\n",
    "\n",
    "y_predicted_test = clf.predict(X_test)\n",
    "\n",
    "print('R_squared:', metrics.r2_score(y_test, y_predicted_test))\n",
    "print('MAPE:', metrics.mean_absolute_percentage_error(y_test, y_predicted_test))\n",
    "print('RMSE:', metrics.mean_squared_error(y_test, y_predicted_test, squared=False))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.5 XGBoost Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_squared: 0.5803051003774975\n",
      "MAPE: 1.0654934881024856\n",
      "RMSE: 8.412553265735943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    }
   ],
   "source": [
    "X_train = standardize(X_train).fillna(0)\n",
    "X_test = standardize(X_test).fillna(0)\n",
    "\n",
    "# Very simple models work better here\n",
    "params = [\n",
    "    {'objective': ['reg:squarederror'],\n",
    "     'n_estimators': np.arange(1, 7, 1),\n",
    "     'eval_metric': ['rmse'],\n",
    "     'max_depth': np.arange(1, 5, 1)}]\n",
    "\n",
    "reg_xgb = GridSearchCV(xgb.XGBRegressor(), params, n_jobs=5, cv=5, scoring='r2')\n",
    "reg_xgb.fit(X_train, y_train)\n",
    "\n",
    "y_predicted_test = reg_xgb.predict(X_test)\n",
    "\n",
    "print('R_squared:', metrics.r2_score(y_test, y_predicted_test))\n",
    "print('MAPE:', metrics.mean_absolute_percentage_error(y_test, y_predicted_test))\n",
    "print('RMSE:', metrics.mean_squared_error(y_test, y_predicted_test, squared=False))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.6 LSTM RNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.7 MTGNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Nomothetic Models Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
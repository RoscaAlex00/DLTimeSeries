{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1-step Forecasting with linear and non-linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import utils\n",
    "\n",
    "# Plot settings\n",
    "plt.rcParams['figure.figsize'] = (16, 8)\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "sns.set()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "    Unnamed: 0  ID               start          finish  drinks  comfortable  \\\n0            1   1 2018-02-06 16:20:00  2/6/2018 16:22       3     7.382609   \n31           2   1 2018-02-06 18:54:00  2/6/2018 18:58       0    14.382609   \n1            3   1 2018-02-06 20:08:00  2/6/2018 20:22       0    15.382609   \n2            4   1 2018-02-06 22:29:00  2/6/2018 22:46       0    21.382609   \n36           5   1 2018-02-07 10:52:00  2/7/2018 11:23       0   -11.617391   \n\n     stressed       down       calm   pressure  ...    cosT.1    sinT.1  \\\n0   -9.817391  10.843478 -37.791304   6.173913  ...  1.000000  0.000000   \n31  47.182609   7.843478   7.208696  10.173913  ...  0.892979  0.450098   \n1   12.182609  10.843478  20.208696  18.173913  ...  0.418660  0.908143   \n2   -5.817391  -2.156522   8.208696   5.173913  ...  0.108867  0.994056   \n36   5.182609   0.843478 -24.791304  -4.826087  ...  0.043619 -0.999048   \n\n     cos2T.1   sin2T.1    cosW.1    sinW.1  dayvar.1  beepvar.1  filter.1  \\\n0   1.000000  0.000000  1.000000  0.000000         1          4         0   \n31  0.594823  0.803857  0.997777  0.066647         1          5         0   \n1  -0.649448  0.760406  0.986795  0.161973         1          6         0   \n2  -0.976296  0.216440  0.978277  0.207302         1          7         0   \n36 -0.996195 -0.087156  0.777930  0.628351         2          1         0   \n\n    consec.1  \n0          1  \n31         2  \n1          3  \n2          4  \n36         7  \n\n[5 rows x 116 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>ID</th>\n      <th>start</th>\n      <th>finish</th>\n      <th>drinks</th>\n      <th>comfortable</th>\n      <th>stressed</th>\n      <th>down</th>\n      <th>calm</th>\n      <th>pressure</th>\n      <th>...</th>\n      <th>cosT.1</th>\n      <th>sinT.1</th>\n      <th>cos2T.1</th>\n      <th>sin2T.1</th>\n      <th>cosW.1</th>\n      <th>sinW.1</th>\n      <th>dayvar.1</th>\n      <th>beepvar.1</th>\n      <th>filter.1</th>\n      <th>consec.1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>2018-02-06 16:20:00</td>\n      <td>2/6/2018 16:22</td>\n      <td>3</td>\n      <td>7.382609</td>\n      <td>-9.817391</td>\n      <td>10.843478</td>\n      <td>-37.791304</td>\n      <td>6.173913</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>2</td>\n      <td>1</td>\n      <td>2018-02-06 18:54:00</td>\n      <td>2/6/2018 18:58</td>\n      <td>0</td>\n      <td>14.382609</td>\n      <td>47.182609</td>\n      <td>7.843478</td>\n      <td>7.208696</td>\n      <td>10.173913</td>\n      <td>...</td>\n      <td>0.892979</td>\n      <td>0.450098</td>\n      <td>0.594823</td>\n      <td>0.803857</td>\n      <td>0.997777</td>\n      <td>0.066647</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>1</td>\n      <td>2018-02-06 20:08:00</td>\n      <td>2/6/2018 20:22</td>\n      <td>0</td>\n      <td>15.382609</td>\n      <td>12.182609</td>\n      <td>10.843478</td>\n      <td>20.208696</td>\n      <td>18.173913</td>\n      <td>...</td>\n      <td>0.418660</td>\n      <td>0.908143</td>\n      <td>-0.649448</td>\n      <td>0.760406</td>\n      <td>0.986795</td>\n      <td>0.161973</td>\n      <td>1</td>\n      <td>6</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>1</td>\n      <td>2018-02-06 22:29:00</td>\n      <td>2/6/2018 22:46</td>\n      <td>0</td>\n      <td>21.382609</td>\n      <td>-5.817391</td>\n      <td>-2.156522</td>\n      <td>8.208696</td>\n      <td>5.173913</td>\n      <td>...</td>\n      <td>0.108867</td>\n      <td>0.994056</td>\n      <td>-0.976296</td>\n      <td>0.216440</td>\n      <td>0.978277</td>\n      <td>0.207302</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>5</td>\n      <td>1</td>\n      <td>2018-02-07 10:52:00</td>\n      <td>2/7/2018 11:23</td>\n      <td>0</td>\n      <td>-11.617391</td>\n      <td>5.182609</td>\n      <td>0.843478</td>\n      <td>-24.791304</td>\n      <td>-4.826087</td>\n      <td>...</td>\n      <td>0.043619</td>\n      <td>-0.999048</td>\n      <td>-0.996195</td>\n      <td>-0.087156</td>\n      <td>0.777930</td>\n      <td>0.628351</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 116 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading alcohol data\n",
    "train_df, test_df, data_raw_list = utils.load_alcohol()\n",
    "\n",
    "combined_data = []\n",
    "\n",
    "for i in range(len(train_df)):\n",
    "    train = train_df[i]\n",
    "    test = test_df[i]\n",
    "    # Combine both train and test sets since the initial split was 50/50\n",
    "    combined = pd.concat([train, test])\n",
    "    # Sort by date\n",
    "    combined['start'] = pd.to_datetime(combined['start'])\n",
    "    combined = combined.sort_values(by='start')\n",
    "    combined_data.append(combined)\n",
    "\n",
    "combined_data[0].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "Patient included in study:\n",
      "[1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 14, 15, 16, 17, 21, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 46, 48, 49, 50, 52, 53, 54, 55, 58, 59, 63, 64, 65, 66, 68, 70, 71, 72, 74, 75, 77]\n"
     ]
    },
    {
     "data": {
      "text/plain": "     Relax_lag  Irritable_lag  Worry_lag  Nervous_lag  Future_lag  \\\n105        1.0            1.0        1.0          1.0         1.0   \n111        2.0            1.0        2.0          2.0         1.0   \n109        2.0            1.0        2.0          2.0         1.0   \n102        2.0            1.0        2.0          2.0         1.0   \n107        2.0            2.0        2.0          2.0         1.0   \n\n     Anhedonia_lag  Tired_lag  Hungry_lag  Alone_lag  Angry_lag  \\\n105            1.0        2.0         2.0        1.0        1.0   \n111            1.0        3.0         1.0        1.0        1.0   \n109            1.0        3.0         1.0        1.0        1.0   \n102            1.0        3.0         1.0        1.0        1.0   \n107            1.0        3.0         2.0        1.0        1.0   \n\n     Social_offline_lag  Social_online_lag  Music_lag  Procrastinate_lag  \\\n105                 3.0                4.0        2.0                3.0   \n111                 1.0                4.0        3.0                1.0   \n109                 2.0                3.0        2.0                2.0   \n102                 3.0                3.0        3.0                2.0   \n107                 2.0                4.0        2.0                1.0   \n\n     Outdoors_lag  C19_occupied_lag  C19_worry_lag  Home_lag  beepvar_lag  \n105           1.0               2.0            2.0       5.0          1.0  \n111           1.0               2.0            2.0       5.0          3.0  \n109           2.0               3.0            3.0       3.0          1.0  \n102           4.0               3.0            3.0       4.0          2.0  \n107           1.0               3.0            3.0       5.0          3.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Relax_lag</th>\n      <th>Irritable_lag</th>\n      <th>Worry_lag</th>\n      <th>Nervous_lag</th>\n      <th>Future_lag</th>\n      <th>Anhedonia_lag</th>\n      <th>Tired_lag</th>\n      <th>Hungry_lag</th>\n      <th>Alone_lag</th>\n      <th>Angry_lag</th>\n      <th>Social_offline_lag</th>\n      <th>Social_online_lag</th>\n      <th>Music_lag</th>\n      <th>Procrastinate_lag</th>\n      <th>Outdoors_lag</th>\n      <th>C19_occupied_lag</th>\n      <th>C19_worry_lag</th>\n      <th>Home_lag</th>\n      <th>beepvar_lag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>105</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>111</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>109</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>102</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>107</th>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading covid data\n",
    "covid_train_x_list, covid_test_x_list, covid_train_y_list, covid_test_y_list = utils.patients_covid()\n",
    "\n",
    "covid_train_x_list[0].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Idiographic Models Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Predict craving\n",
    "\n",
    "# Make own splits\n",
    "def prepare_data_own(idx, combined_list, random_state):\n",
    "    # print('Patient ID:', combined_list[idx].iloc[0]['ID'])\n",
    "    X = combined_list[idx].drop(combined_list[idx].columns[range(0, 24)], axis=1).fillna(0)\n",
    "    y = combined_list[idx]['craving']\n",
    "\n",
    "    return train_test_split(X, y, test_size=0.3, random_state=random_state)\n",
    "\n",
    "\n",
    "# Split into dependent/independent features\n",
    "def prepare_data(idx, train_list, test_list):\n",
    "    # print('Patient ID:', train_list[idx]['ID'][0])\n",
    "\n",
    "    X_train = train_list[idx].drop(train_list[idx].columns[range(0, 61)], axis=1).fillna(0)\n",
    "    y_train = train_list[idx]['craving']\n",
    "    X_test = test_list[idx].drop(test_list[idx].columns[range(0, 61)], axis=1).fillna(0)\n",
    "    y_test = test_list[idx]['craving']\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1 Elastic-Net Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_squared: 0.3105248292112299\n",
      "MAPE: 0.868046768759073\n",
      "RMSE: 20.394294809977133\n",
      "MAE: 16.71060148405697\n",
      "CORR: 0.5610027960444378\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = prepare_data(1, train_list=train_df, test_list=test_df)\n",
    "\n",
    "\n",
    "# Train an elastic-net model\n",
    "# Tests sets here are fore testing purposes\n",
    "def elastic_net(train_x, train_y, test_x, test_y, vis):\n",
    "    # Standardize data\n",
    "    X_train_loc = utils.standardize(train_x).fillna(0)\n",
    "    X_test_loc = utils.standardize(test_x).fillna(0)\n",
    "\n",
    "    # Train model with 5-fold cross-validation\n",
    "    l1_ratios = np.arange(0.01, 0.6, 0.05)\n",
    "    elastic_reg = lm.ElasticNetCV(alphas=np.arange(0.01, 20, 0.05), l1_ratio=l1_ratios, cv=5, max_iter=100000,\n",
    "                                  fit_intercept=True)\n",
    "    elastic_reg.fit(X_train_loc, train_y)\n",
    "    y_predicted_test = elastic_reg.predict(X_test_loc)\n",
    "    # print('--- Elastic-Net Results ---')\n",
    "    # print()\n",
    "    # Show results for current test set if vis is set to True\n",
    "    utils.eval_results(actual=test_y, predicted=y_predicted_test, show=vis)\n",
    "\n",
    "    return elastic_reg\n",
    "\n",
    "\n",
    "m = elastic_net(X_train, y_train, X_test, y_test, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 Linear SVM Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_squared: 0.31290514874622954\n",
      "MAPE: 0.8226844555502397\n",
      "RMSE: 20.359060104230863\n",
      "MAE: 15.756742447506781\n",
      "CORR: 0.5713855335010715\n"
     ]
    }
   ],
   "source": [
    "def linear_svm(train_x, train_y, test_x, test_y, vis, params):\n",
    "    # Standardize data\n",
    "    X_train_loc = utils.standardize(train_x).fillna(0)\n",
    "    X_test_loc = utils.standardize(test_x).fillna(0)\n",
    "\n",
    "    # Train over the hyperparameter grid with 5-fold CV\n",
    "    clf = GridSearchCV(estimator=LinearSVR(), param_grid=params, scoring='neg_mean_absolute_error', cv=5)\n",
    "    clf.fit(X_train_loc, train_y)\n",
    "    # best_params = clf.best_params_\n",
    "    # print(best_params)\n",
    "    y_predicted_test = clf.predict(X_test_loc)\n",
    "\n",
    "    # print('--- Linear-SVM Results ---')\n",
    "    # print()\n",
    "    utils.eval_results(actual=test_y, predicted=y_predicted_test, show=vis)\n",
    "    return clf\n",
    "\n",
    "\n",
    "param = [\n",
    "    {'C': np.arange(0.1, 4, 0.1),\n",
    "     'epsilon': np.arange(6, 7, 0.1),\n",
    "     'loss': ['epsilon_insensitive'],\n",
    "     'fit_intercept': [True],\n",
    "     'max_iter': [10000]}]\n",
    "\n",
    "m = linear_svm(X_train, y_train, X_test, y_test, True, param)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3 K-NN Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_squared: 0.1254204616378809\n",
      "MAPE: 1.0122225548421209\n",
      "RMSE: 22.969367355995985\n",
      "MAE: 17.183673469387752\n",
      "CORR: 0.49538301761540343\n"
     ]
    }
   ],
   "source": [
    "# k-Nearest Neighbors Model\n",
    "def knn_reg(train_x, train_y, test_x, test_y, vis):\n",
    "    params = [\n",
    "        {'weights': ['uniform', 'distance'],\n",
    "         'n_neighbors': np.arange(2, 20, 1)}]\n",
    "\n",
    "    # Train with 5-fold CV\n",
    "    clf = GridSearchCV(estimator=KNeighborsRegressor(), param_grid=params, scoring='neg_mean_absolute_error', cv=5)\n",
    "    clf.fit(train_x, train_y)\n",
    "\n",
    "    y_predicted_test = clf.predict(test_x)\n",
    "\n",
    "    mse, rmse, mae = utils.eval_results(actual=test_y, predicted=y_predicted_test, show=vis)\n",
    "    return mse, rmse, mae\n",
    "\n",
    "\n",
    "m = knn_reg(X_train, y_train, X_test, y_test, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.4 XGBoost Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_squared: 0.1821370000722441\n",
      "MAPE: 0.7982178684822807\n",
      "RMSE: 22.21210194284715\n",
      "MAE: 16.118310809097522\n",
      "CORR: 0.5150857953119794\n"
     ]
    }
   ],
   "source": [
    "def xgboost_reg(train_x, train_y, test_x, test_y, vis):\n",
    "    # Very simple models work better here, since there are few data points\n",
    "    # Hyperparameter grid\n",
    "    params = [\n",
    "        {'objective': ['reg:squarederror'],\n",
    "         'n_estimators': [1, 3, 5, 7, 10, 20, 30],\n",
    "         'eval_metric': ['mae'],\n",
    "         'max_depth': np.arange(1, 8, 1)}]\n",
    "\n",
    "    # Train a model with 5-fold CV\n",
    "    reg_xgb = GridSearchCV(xgb.XGBRegressor(), params, n_jobs=5, cv=5, scoring='neg_mean_absolute_error')\n",
    "    reg_xgb.fit(train_x, train_y)\n",
    "\n",
    "    # print(reg_xgb.best_params_)\n",
    "    y_predicted_test = reg_xgb.predict(test_x)\n",
    "\n",
    "    utils.eval_results(actual=test_y, predicted=y_predicted_test, show=vis)\n",
    "    return reg_xgb\n",
    "\n",
    "\n",
    "m = xgboost_reg(X_train, y_train, X_test, y_test, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.5 Random Forests"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_squared: 0.1979255588006522\n",
      "MAPE: 0.8478998175324122\n",
      "RMSE: 21.996658687885926\n",
      "MAE: 16.372407852405743\n",
      "CORR: 0.5134327027501486\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to train a random forests model\n",
    "def random_forests(train_x, train_y, test_x, test_y, vis):\n",
    "    # Hyperparameter grid\n",
    "    grid = [\n",
    "        {'n_estimators': [25, 50, 70, 100],\n",
    "         'max_features': ['auto', 'sqrt'],\n",
    "         'max_depth': [3, 5, 10, 15],\n",
    "         'min_samples_split': [2, 4, 6],\n",
    "         'min_samples_leaf': [1],\n",
    "         'bootstrap': [True]}]\n",
    "\n",
    "    # Train with 5-fold CV\n",
    "    rf = GridSearchCV(RandomForestRegressor(), param_grid=grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "    rf.fit(train_x, train_y)\n",
    "    y_predicted_test = rf.predict(test_x)\n",
    "    # print(rf.best_params_)\n",
    "\n",
    "    utils.eval_results(actual=test_y, predicted=y_predicted_test, show=vis)\n",
    "\n",
    "    return rf\n",
    "\n",
    "\n",
    "m = random_forests(X_train, y_train, X_test, y_test, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.6 3-Layer LSTM RNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_squared: 0.10627963612609737\n",
      "MAPE: 0.8480162451169719\n",
      "RMSE: 23.219357820400273\n",
      "MAE: 20.06258435969388\n",
      "CORR: 0.479508996875319\n"
     ]
    }
   ],
   "source": [
    "import keras.layers as layer\n",
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "# Train a NN with 3 LSTM units\n",
    "def lstm_rnn(train_x, train_y, test_x, test_y, vis):\n",
    "    # Standardize and transform both the train and test sets\n",
    "    X_train_loc = utils.standardize(train_x).fillna(0)\n",
    "    X_test_loc = utils.standardize(test_x).fillna(0)\n",
    "    train_x_val, train_y_val, test_x_val, test_y_val = X_train_loc.values, train_y.values, X_test_loc.values, test_y.values\n",
    "\n",
    "    train_x_val = train_x_val.reshape((train_x_val.shape[0], 1, train_x_val.shape[1]))\n",
    "    test_x_val = test_x_val.reshape((test_x_val.shape[0], 1, test_x_val.shape[1]))\n",
    "\n",
    "    # Neural network architecture\n",
    "    model = Sequential([\n",
    "        layer.Input(shape=(train_x_val.shape[1], train_x_val.shape[2])),\n",
    "        layer.LSTM(40, return_sequences=True),\n",
    "        layer.Dropout(0.25),\n",
    "        layer.LSTM(units=25, return_sequences=True),\n",
    "        layer.Dropout(0.20),\n",
    "        layer.LSTM(units=10, return_sequences=False),\n",
    "        layer.Dense(units=1, activation='linear')\n",
    "    ])\n",
    "    # Compile and train model\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    model.fit(train_x_val, train_y_val, epochs=40, batch_size=4, verbose=0, shuffle=False)\n",
    "\n",
    "    y_predicted_test = model.predict(test_x_val)\n",
    "\n",
    "    utils.eval_results(actual=test_y, predicted=y_predicted_test.flatten(), show=vis)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "m = lstm_rnn(X_train, y_train, X_test, y_test, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.7 1-Layer LSTM RNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_squared: 0.10494309116974765\n",
      "MAPE: 0.8153613392211038\n",
      "RMSE: 23.236713428986565\n",
      "MAE: 19.303847946569814\n",
      "CORR: 0.5146627462122909\n"
     ]
    }
   ],
   "source": [
    "# Train a NN with 1 LSTM unit\n",
    "def one_lstm_rnn(train_x, train_y, test_x, test_y, vis):\n",
    "    # Standardize and transform both the train and test sets\n",
    "    X_train_loc = utils.standardize(train_x).fillna(0)\n",
    "    X_test_loc = utils.standardize(test_x).fillna(0)\n",
    "    train_x_val, train_y_val, test_x_val, test_y_val = X_train_loc.values, train_y.values, X_test_loc.values, test_y.values\n",
    "\n",
    "    train_x_val = train_x_val.reshape((train_x_val.shape[0], 1, train_x_val.shape[1]))\n",
    "    test_x_val = test_x_val.reshape((test_x_val.shape[0], 1, test_x_val.shape[1]))\n",
    "\n",
    "    # Neural network architecture\n",
    "    model = Sequential([\n",
    "        layer.Input(shape=(train_x_val.shape[1], train_x_val.shape[2])),\n",
    "        layer.Bidirectional(layer.LSTM(32, return_sequences=True)),\n",
    "        layer.Dropout(0.25),\n",
    "        layer.Dense(units=1, activation='linear')\n",
    "    ])\n",
    "    # Compile and train model\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    model.fit(train_x_val, train_y_val, epochs=40, batch_size=4, verbose=0, shuffle=False)\n",
    "\n",
    "    y_predicted_test = model.predict(test_x_val)\n",
    "\n",
    "    utils.eval_results(actual=test_y, predicted=y_predicted_test.flatten(), show=vis)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "m = one_lstm_rnn(X_train, y_train, X_test, y_test, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.8 Gated Recurrent Unit (GRU) Network"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_squared: 0.062416719571667945\n",
      "MAPE: 0.831929922563883\n",
      "RMSE: 23.782324713515887\n",
      "MAE: 18.680932349506886\n",
      "CORR: 0.4091086041508172\n"
     ]
    }
   ],
   "source": [
    "# Train a NN with GRU units\n",
    "def gru_rnn(train_x, train_y, test_x, test_y, vis):\n",
    "    # Standardize and transform both the train and test sets\n",
    "    X_train_loc = utils.standardize(train_x).fillna(0)\n",
    "    X_test_loc = utils.standardize(test_x).fillna(0)\n",
    "    train_x_val, train_y_val, test_x_val, test_y_val = X_train_loc.values, train_y.values, X_test_loc.values, test_y.values\n",
    "\n",
    "    train_x_val = train_x_val.reshape((train_x_val.shape[0], 1, train_x_val.shape[1]))\n",
    "    test_x_val = test_x_val.reshape((test_x_val.shape[0], 1, test_x_val.shape[1]))\n",
    "\n",
    "    # Neural network architecture\n",
    "    model = Sequential([\n",
    "        layer.Input(shape=(train_x_val.shape[1], train_x_val.shape[2])),\n",
    "        layer.Bidirectional(layer.GRU(units=24)),\n",
    "        layer.RepeatVector(train_x_val.shape[1]),\n",
    "        layer.Bidirectional(layer.GRU(units=24, return_sequences=True)),\n",
    "        layer.TimeDistributed(layer.Dense(units=1, activation='linear'))\n",
    "    ])\n",
    "    # Compile and train model\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    model.fit(train_x_val, train_y_val, epochs=75, batch_size=4, verbose=0, shuffle=False)\n",
    "\n",
    "    y_predicted_test = model.predict(test_x_val)\n",
    "\n",
    "    utils.eval_results(actual=test_y, predicted=y_predicted_test.flatten(), show=vis)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "m = gru_rnn(X_train, y_train, X_test, y_test, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1 Evaluating Performance on Entire Dataset (Alcohol Data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000264E71D2160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000265834B3EE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "---- Elastic-Net Results ----\n",
      "Average MAPE: 1.4156218369947697\n",
      "Average RMSE: 14.771363649360774\n",
      "Average MAE: 10.985510678456176\n",
      "---------------------------------\n",
      "---- Linear SVM Results ----\n",
      "Average MAPE: 1.3381442360655964\n",
      "Average RMSE: 14.318360706906935\n",
      "Average MAE: 10.336085267389095\n",
      "---------------------------------\n",
      "---- XGBoost Results ----\n",
      "Average MAPE: 1.5293373988299914\n",
      "Average RMSE: 15.398592744621979\n",
      "Average MAE: 10.916741750513548\n",
      "---------------------------------\n",
      "---- Random Forest Results ----\n",
      "Average MAPE: 1.4978067336955818\n",
      "Average RMSE: 14.57025393875546\n",
      "Average MAE: 10.511815149209964\n",
      "---------------------------------\n",
      "---- LSTM Results ----\n",
      "Average MAPE: 1.2389742477919439\n",
      "Average RMSE: 15.522262435974843\n",
      "Average MAE: 10.49470659739127\n",
      "---------------------------------\n",
      "---- 1-LSTM Results ----\n",
      "Average MAPE: 1.1035621917865843\n",
      "Average RMSE: 16.057122221347466\n",
      "Average MAE: 10.882175557481919\n",
      "---------------------------------\n",
      "---- GRU Results ----\n",
      "Average MAPE: 1.3453924017604908\n",
      "Average RMSE: 16.660736861095224\n",
      "Average MAE: 11.005937368813482\n",
      "---------------------------------\n",
      "Included patient list:\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "\n",
    "# Function to evaluate the models on the 'Alcohol' dataset\n",
    "def evaluate_models(train_list, test_list):\n",
    "    assert len(train_list) == len(test_list)\n",
    "    # Lists to hold the metrics for all patients and models\n",
    "    mse_elastic, mse_svm, mse_one_lstm, mse_xgb, mse_rf, mse_lstm, mse_gru = ([] for _ in range(7))\n",
    "    rmse_elastic, rmse_svm, rmse_one_lstm, rmse_xgb, rmse_rf, rmse_lstm, rmse_gru = ([] for _ in range(7))\n",
    "    mae_elastic, mae_svm, mae_one_lstm, mae_xgb, mae_rf, mae_lstm, mae_gru = ([] for _ in range(7))\n",
    "\n",
    "    patient_ids = []\n",
    "    # Write out the results to a text file\n",
    "    f = open(\"output_idiographic_a.txt\", \"a\")\n",
    "    f.write('- - - PER INDIVIDUAL RESULTS - - -\\n')\n",
    "    for x in range(len(train_list)):\n",
    "        # Build and evaluate a model for every single patient\n",
    "        train_x, test_x, train_y, test_y = prepare_data(x, train_list=train_list, test_list=test_list)\n",
    "        # Elastic-Net (baseline)\n",
    "        elastic = elastic_net(train_x, train_y, test_x, test_y, False)\n",
    "        mse, rmse, mae = utils.eval_results(test_y, elastic.predict(utils.standardize(test_x).fillna(0)), False)\n",
    "        # Elastic-Net metrics\n",
    "        patient_ids.append(train_list[x]['ID'][0])\n",
    "        mse_elastic.append(mse)\n",
    "        rmse_elastic.append(rmse)\n",
    "        mae_elastic.append(mae)\n",
    "\n",
    "        f.write(\"Patient ID: %s\\n\" % train_list[x]['ID'][0])\n",
    "        f.write('\\n')\n",
    "        f.write('--- Elastic-Net ---\\n')\n",
    "        f.write(\"MSE: %s\\n\" % mse)\n",
    "        f.write(\"RMSE: %s\\n\" % rmse)\n",
    "        f.write(\"MAE: %s\\n\" % mae)\n",
    "        f.write('\\n')\n",
    "\n",
    "        # Linear-SVM\n",
    "\n",
    "        params = [\n",
    "            {'C': np.arange(0.1, 4, 0.1),\n",
    "             'epsilon': np.arange(6, 7, 0.1),\n",
    "             'loss': ['epsilon_insensitive'],\n",
    "             'fit_intercept': [True],\n",
    "             'max_iter': [10000]}]\n",
    "\n",
    "        svm = linear_svm(train_x, train_y, test_x, test_y, False, params)\n",
    "        mse, rmse, mae = utils.eval_results(test_y, svm.predict(utils.standardize(test_x).fillna(0)), False)\n",
    "        # Linear-SVM metrics\n",
    "        mse_svm.append(mse)\n",
    "        rmse_svm.append(rmse)\n",
    "        mae_svm.append(mae)\n",
    "\n",
    "        f.write('--- Linear-SVM ---\\n')\n",
    "        f.write(\"MSE: %s\\n\" % mse)\n",
    "        f.write(\"RMSE: %s\\n\" % rmse)\n",
    "        f.write(\"MAE: %s\\n\" % mae)\n",
    "        f.write('\\n')\n",
    "\n",
    "        # XGBoost Regression\n",
    "        xgboost = xgboost_reg(train_x, train_y, test_x, test_y, False)\n",
    "        mse, rmse, mae = utils.eval_results(test_y, xgboost.predict(test_x), False)\n",
    "        # XGBoost metrics\n",
    "        mse_xgb.append(mse)\n",
    "        rmse_xgb.append(rmse)\n",
    "        mae_xgb.append(mae)\n",
    "\n",
    "        f.write('--- XGBoost ---\\n')\n",
    "        f.write(\"MSE: %s\\n\" % mse)\n",
    "        f.write(\"RMSE: %s\\n\" % rmse)\n",
    "        f.write(\"MAE: %s\\n\" % mae)\n",
    "        f.write('\\n')\n",
    "\n",
    "        # RF\n",
    "        rf = random_forests(train_x, train_y, test_x, test_y, False)\n",
    "        mse, rmse, mae = utils.eval_results(test_y, rf.predict(test_x), False)\n",
    "        # RF metrics\n",
    "        mse_rf.append(mse)\n",
    "        rmse_rf.append(rmse)\n",
    "        mae_rf.append(mae)\n",
    "\n",
    "        f.write('--- Random Forests ---\\n')\n",
    "        f.write(\"MSE: %s\\n\" % mse)\n",
    "        f.write(\"RMSE: %s\\n\" % rmse)\n",
    "        f.write(\"MAE: %s\\n\" % mae)\n",
    "        f.write('\\n')\n",
    "\n",
    "        # LSTM 3-Layer RNN\n",
    "        test_x_val = utils.standardize(test_x).fillna(0).values\n",
    "        test_x_val = test_x_val.reshape((test_x_val.shape[0], 1, test_x_val.shape[1]))\n",
    "        lstm = lstm_rnn(train_x, train_y, test_x, test_y, False)\n",
    "        mse, rmse, mae = utils.eval_results(test_y, lstm.predict(test_x_val).flatten(),\n",
    "                                            False)\n",
    "        # LSTM metrics\n",
    "        mse_lstm.append(mse)\n",
    "        rmse_lstm.append(rmse)\n",
    "        mae_lstm.append(mae)\n",
    "\n",
    "        f.write('--- LSTM RNN ---\\n')\n",
    "        f.write(\"MSE: %s\\n\" % mse)\n",
    "        f.write(\"RMSE: %s\\n\" % rmse)\n",
    "        f.write(\"MAE: %s\\n\" % mae)\n",
    "        f.write('\\n')\n",
    "\n",
    "        # LSTM 1-Layer RNN\n",
    "        lstm_one = one_lstm_rnn(train_x, train_y, test_x, test_y, False)\n",
    "        mse, rmse, mae = utils.eval_results(test_y, lstm_one.predict(test_x_val).flatten(), False)\n",
    "        # LSTM metrics\n",
    "        mse_one_lstm.append(mse)\n",
    "        rmse_one_lstm.append(rmse)\n",
    "        mae_one_lstm.append(mae)\n",
    "\n",
    "        f.write('--- 1-LSTM RNN ---\\n')\n",
    "        f.write(\"MSE: %s\\n\" % mse)\n",
    "        f.write(\"RMSE: %s\\n\" % rmse)\n",
    "        f.write(\"MAE: %s\\n\" % mae)\n",
    "        f.write('\\n')\n",
    "\n",
    "        # GRU RNN\n",
    "        gru = gru_rnn(train_x, train_y, test_x, test_y, False)\n",
    "        mse, rmse, mae = utils.eval_results(test_y, gru.predict(test_x_val).flatten(), False)\n",
    "\n",
    "        # GRU metrics\n",
    "        mse_gru.append(mse)\n",
    "        rmse_gru.append(rmse)\n",
    "        mae_gru.append(mae)\n",
    "\n",
    "        f.write('--- GRU RNN ---\\n')\n",
    "        f.write(\"MSE: %s\\n\" % mse)\n",
    "        f.write(\"RMSE: %s\\n\" % rmse)\n",
    "        f.write(\"MAE: %s\\n\" % mae)\n",
    "        f.write('\\n')\n",
    "\n",
    "    f.close()\n",
    "    # Print out the average metrics for all models\n",
    "    print('---- Elastic-Net Results ----')\n",
    "    utils.average_metrics(mse_elastic, rmse_elastic, mae_elastic)\n",
    "    print('---------------------------------')\n",
    "    print('---- Linear SVM Results ----')\n",
    "    utils.average_metrics(mse_svm, rmse_svm, mae_svm)\n",
    "    print('---------------------------------')\n",
    "    print('---- XGBoost Results ----')\n",
    "    utils.average_metrics(mse_xgb, rmse_xgb, mae_xgb)\n",
    "    print('---------------------------------')\n",
    "    print('---- Random Forest Results ----')\n",
    "    utils.average_metrics(mse_rf, rmse_rf, mae_rf)\n",
    "    print('---------------------------------')\n",
    "    print('---- LSTM Results ----')\n",
    "    utils.average_metrics(mse_lstm, rmse_lstm, mae_lstm)\n",
    "    print('---------------------------------')\n",
    "    print('---- 1-LSTM Results ----')\n",
    "    utils.average_metrics(mse_one_lstm, rmse_one_lstm, mae_one_lstm)\n",
    "    print('---------------------------------')\n",
    "    print('---- GRU Results ----')\n",
    "    utils.average_metrics(mse_gru, rmse_gru, mae_gru)\n",
    "    print('---------------------------------')\n",
    "\n",
    "    print('Included patient list:')\n",
    "    print(patient_ids)\n",
    "\n",
    "    # For the box-plot later\n",
    "    rmse_overall = rmse_elastic + rmse_svm + rmse_xgb + rmse_rf + rmse_lstm + rmse_one_lstm + rmse_gru\n",
    "    n = len(rmse_rf)\n",
    "    model_names = ['Elastic Net'] * n + ['SVM'] * n + ['XGBoost'] * n + ['RF'] * n + ['3-Layer LSTM'] * n + [\n",
    "        '1-Layer LSTM'] * n + ['GRU'] * n\n",
    "    dataset = ['Alcohol'] * len(model_names)\n",
    "\n",
    "    return rmse_overall, model_names, dataset\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "rmse_alcohol, models_alcohol, data_alcohol = evaluate_models(train_df, test_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 Evaluating Performance on Entire Dataset (COVID-19 Data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Elastic-Net Results ----\n",
      "Average MAPE: 0.32979460124367505\n",
      "Average RMSE: 0.6788114939714779\n",
      "Average MAE: 0.5291089375122295\n",
      "---------------------------------\n",
      "---- Linear SVM Results ----\n",
      "Average MAPE: 0.3440432159605041\n",
      "Average RMSE: 0.8307069538132562\n",
      "Average MAE: 0.6160700652560498\n",
      "---------------------------------\n",
      "---- XGBoost Results ----\n",
      "Average MAPE: 0.2922642470519952\n",
      "Average RMSE: 0.7337463477865799\n",
      "Average MAE: 0.5173483196531824\n",
      "---------------------------------\n",
      "---- Random Forest Results ----\n",
      "Average MAPE: 0.3236329104090252\n",
      "Average RMSE: 0.6851011083654976\n",
      "Average MAE: 0.514198926554742\n",
      "---------------------------------\n",
      "---- LSTM Results ----\n",
      "Average MAPE: 0.2997230792472303\n",
      "Average RMSE: 0.7336533766372688\n",
      "Average MAE: 0.543805269649105\n",
      "---------------------------------\n",
      "---- 1-LSTM Results ----\n",
      "Average MAPE: 0.3635815166655401\n",
      "Average RMSE: 0.9351832308000557\n",
      "Average MAE: 0.7043744473238097\n",
      "---------------------------------\n",
      "---- GRU Results ----\n",
      "Average MAPE: 0.33026068598843783\n",
      "Average RMSE: 0.8189109908641988\n",
      "Average MAE: 0.6067607139657475\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Function to evaluate the models on the COVID-19 dataset\n",
    "def evaluate_models(covid_train_x, covid_test_x, covid_train_y, covid_test_y):\n",
    "    # Lists to hold the metrics for all patients and models\n",
    "    mse_elastic, mse_svm, mse_one_lstm, mse_xgb, mse_rf, mse_lstm, mse_gru = ([] for _ in range(7))\n",
    "    rmse_elastic, rmse_svm, rmse_one_lstm, rmse_xgb, rmse_rf, rmse_lstm, rmse_gru = ([] for _ in range(7))\n",
    "    mae_elastic, mae_svm, mae_one_lstm, mae_xgb, mae_rf, mae_lstm, mae_gru = ([] for _ in range(7))\n",
    "\n",
    "    # Write the results to a text file\n",
    "    f = open(\"output_idiographic_c.txt\", \"a\")\n",
    "    f.write('- - - PER INDIVIDUAL RESULTS - - -\\n')\n",
    "\n",
    "    for z in range(len(covid_train_x_list)):\n",
    "        # Build and evaluate a model for every single patient\n",
    "\n",
    "        # Elastic-Net (baseline)\n",
    "        elastic = elastic_net(covid_train_x[z], covid_train_y[z], covid_test_x[z], covid_test_y[z], False)\n",
    "        mse, rmse, mae = utils.eval_results(covid_test_y_list[z],\n",
    "                                            elastic.predict(utils.standardize(covid_test_x_list[z]).fillna(0)),\n",
    "                                            False)\n",
    "\n",
    "        # Elastic-Net metrics\n",
    "        mse_elastic.append(mse)\n",
    "        rmse_elastic.append(rmse)\n",
    "        mae_elastic.append(mae)\n",
    "\n",
    "        f.write(\"Patient ID: %s\\n\" % z)\n",
    "        f.write('\\n')\n",
    "        f.write('--- Elastic-Net ---\\n')\n",
    "        f.write(\"MSE: %s\\n\" % mse)\n",
    "        f.write(\"RMSE: %s\\n\" % rmse)\n",
    "        f.write(\"MAE: %s\\n\" % mae)\n",
    "        f.write('\\n')\n",
    "\n",
    "        # Linear-SVM\n",
    "\n",
    "        params = [\n",
    "            {'C': np.arange(0.1, 2, 0.1),\n",
    "             'epsilon': np.arange(0, 0.5, 0.1),\n",
    "             'loss': ['epsilon_insensitive'],\n",
    "             'fit_intercept': [True],\n",
    "             'max_iter': [10000]}]\n",
    "\n",
    "        svm = linear_svm(covid_train_x[z], covid_train_y[z], covid_test_x[z], covid_test_y[z], False, params)\n",
    "        mse, rmse, mae = utils.eval_results(covid_test_y_list[z],\n",
    "                                            svm.predict(utils.standardize(covid_test_x_list[z]).fillna(0)),\n",
    "                                            False)\n",
    "        # Linear-SVM metrics\n",
    "        mse_svm.append(mse)\n",
    "        rmse_svm.append(rmse)\n",
    "        mae_svm.append(mae)\n",
    "\n",
    "        f.write('--- Linear-SVM ---\\n')\n",
    "        f.write(\"MSE: %s\\n\" % mse)\n",
    "        f.write(\"RMSE: %s\\n\" % rmse)\n",
    "        f.write(\"MAE: %s\\n\" % mae)\n",
    "        f.write('\\n')\n",
    "\n",
    "        # XGBoost Regression\n",
    "        xgb_covid = xgboost_reg(covid_train_x[z], covid_train_y[z], covid_test_x[z], covid_test_y[z], False)\n",
    "        mse, rmse, mae = utils.eval_results(covid_test_y_list[z], xgb_covid.predict(covid_test_x_list[z]), False)\n",
    "        # XGBoost metrics\n",
    "        mse_xgb.append(mse)\n",
    "        rmse_xgb.append(rmse)\n",
    "        mae_xgb.append(mae)\n",
    "\n",
    "        f.write('--- XGBoost ---\\n')\n",
    "        f.write(\"MSE: %s\\n\" % mse)\n",
    "        f.write(\"RMSE: %s\\n\" % rmse)\n",
    "        f.write(\"MAE: %s\\n\" % mae)\n",
    "        f.write('\\n')\n",
    "\n",
    "        # RF\n",
    "        rf_covid = random_forests(covid_train_x[z], covid_train_y[z], covid_test_x[z], covid_test_y[z], False)\n",
    "        mse, rmse, mae = utils.eval_results(covid_test_y_list[z], rf_covid.predict(covid_test_x_list[z]), False)\n",
    "        # RF metrics\n",
    "        mse_rf.append(mse)\n",
    "        rmse_rf.append(rmse)\n",
    "        mae_rf.append(mae)\n",
    "\n",
    "        f.write('--- Random Forests ---\\n')\n",
    "        f.write(\"MSE: %s\\n\" % mse)\n",
    "        f.write(\"RMSE: %s\\n\" % rmse)\n",
    "        f.write(\"MAE: %s\\n\" % mae)\n",
    "        f.write('\\n')\n",
    "\n",
    "        # LSTM 3-Layer RNN\n",
    "        test_x_val = utils.standardize(covid_test_x[z]).fillna(0).values\n",
    "        test_x_val = test_x_val.reshape((test_x_val.shape[0], 1, test_x_val.shape[1]))\n",
    "        lstm_covid = lstm_rnn(covid_train_x[z], covid_train_y[z], covid_test_x[z], covid_test_y[z], False)\n",
    "        mse, rmse, mae = utils.eval_results(covid_test_y_list[z],\n",
    "                                            lstm_covid.predict(test_x_val).flatten(),\n",
    "                                            False)\n",
    "        # LSTM metrics\n",
    "        mse_lstm.append(mse)\n",
    "        rmse_lstm.append(rmse)\n",
    "        mae_lstm.append(mae)\n",
    "\n",
    "        f.write('--- LSTM RNN ---\\n')\n",
    "        f.write(\"MSE: %s\\n\" % mse)\n",
    "        f.write(\"RMSE: %s\\n\" % rmse)\n",
    "        f.write(\"MAE: %s\\n\" % mae)\n",
    "        f.write('\\n')\n",
    "\n",
    "        # LSTM 1-Layer RNN\n",
    "        lstm1_covid = one_lstm_rnn(covid_train_x[z], covid_train_y[z], covid_test_x[z], covid_test_y[z], False)\n",
    "        mse, rmse, mae = utils.eval_results(covid_test_y_list[z],\n",
    "                                            lstm1_covid.predict(test_x_val).flatten(),\n",
    "                                            False)\n",
    "        # LSTM metrics\n",
    "        mse_one_lstm.append(mse)\n",
    "        rmse_one_lstm.append(rmse)\n",
    "        mae_one_lstm.append(mae)\n",
    "\n",
    "        f.write('--- 1-LSTM RNN ---\\n')\n",
    "        f.write(\"MSE: %s\\n\" % mse)\n",
    "        f.write(\"RMSE: %s\\n\" % rmse)\n",
    "        f.write(\"MAE: %s\\n\" % mae)\n",
    "        f.write('\\n')\n",
    "\n",
    "        # GRU RNN\n",
    "        gru = gru_rnn(covid_train_x[z], covid_train_y[z], covid_test_x[z], covid_test_y[z], False)\n",
    "        mse, rmse, mae = utils.eval_results(covid_test_y_list[z], gru.predict(test_x_val).flatten(), False)\n",
    "\n",
    "        # GRU metrics\n",
    "        mse_gru.append(mse)\n",
    "        rmse_gru.append(rmse)\n",
    "        mae_gru.append(mae)\n",
    "\n",
    "        f.write('--- GRU RNN ---\\n')\n",
    "        f.write(\"MSE: %s\\n\" % mse)\n",
    "        f.write(\"RMSE: %s\\n\" % rmse)\n",
    "        f.write(\"MAE: %s\\n\" % mae)\n",
    "        f.write('\\n')\n",
    "\n",
    "    f.close()\n",
    "    # Print out the average metrics for every model\n",
    "    print('---- Elastic-Net Results ----')\n",
    "    utils.average_metrics(mse_elastic, rmse_elastic, mae_elastic)\n",
    "    print('---------------------------------')\n",
    "    print('---- Linear SVM Results ----')\n",
    "    utils.average_metrics(mse_svm, rmse_svm, mae_svm)\n",
    "    print('---------------------------------')\n",
    "    print('---- XGBoost Results ----')\n",
    "    utils.average_metrics(mse_xgb, rmse_xgb, mae_xgb)\n",
    "    print('---------------------------------')\n",
    "    print('---- Random Forest Results ----')\n",
    "    utils.average_metrics(mse_rf, rmse_rf, mae_rf)\n",
    "    print('---------------------------------')\n",
    "    print('---- LSTM Results ----')\n",
    "    utils.average_metrics(mse_lstm, rmse_lstm, mae_lstm)\n",
    "    print('---------------------------------')\n",
    "    print('---- 1-LSTM Results ----')\n",
    "    utils.average_metrics(mse_one_lstm, rmse_one_lstm, mae_one_lstm)\n",
    "    print('---------------------------------')\n",
    "    print('---- GRU Results ----')\n",
    "    utils.average_metrics(mse_gru, rmse_gru, mae_gru)\n",
    "    print('---------------------------------')\n",
    "\n",
    "    # For the box-plot later\n",
    "    rmse_overall = rmse_elastic + rmse_svm + rmse_xgb + rmse_rf + rmse_lstm + rmse_one_lstm + rmse_gru\n",
    "    n = len(rmse_rf)\n",
    "    model_names = ['Elastic Net'] * n + ['SVM'] * n + ['XGBoost'] * n + ['RF'] * n + ['3-Layer LSTM'] * n + [\n",
    "        '1-Layer LSTM'] * n + ['GRU'] * n\n",
    "    dataset = ['COVID-19'] * len(model_names)\n",
    "\n",
    "    return rmse_overall, model_names, dataset\n",
    "\n",
    "\n",
    "rmse_covid, models_covid, data_covid = evaluate_models(covid_train_x_list, covid_test_x_list, covid_train_y_list,\n",
    "                                                       covid_test_y_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 3, 2, 7, 6, 3, 6, 2, 6, 7, 4, 2, 5, 3, 1, 9, 5, 3, 4, 3]\n",
      "['RF', 'RF', 'RF', 'RF', 'RF', 'RF', 'RF', 'RF', 'RF', 'RF', 'XGBoost', 'XGBoost', 'XGBoost', 'XGBoost', 'XGBoost', 'XGBoost', 'XGBoost', 'XGBoost', 'XGBoost', 'XGBoost']\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 2400x1200 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate a box-plot for the RMSE values\n",
    "rmse = rmse_alcohol + rmse_covid\n",
    "models = models_alcohol + models_covid\n",
    "dataset_names = data_alcohol + data_covid\n",
    "\n",
    "dictionary = {'RMSE': rmse, 'Model': models, 'Dataset': dataset_names}\n",
    "df = pd.DataFrame(data=dictionary)\n",
    "boxplot = sns.catplot(x='Model', y='RMSE', col='Dataset',\n",
    "                      data=df, kind=\"box\",\n",
    "                      height=4, aspect=.7)\n",
    "# boxplot = sns.boxplot(data=df, y='RMSE', x='Model', palette=\"Set3\")\n",
    "boxplot.set(title='RMSE Values For All Individuals', ylabel='RMSE')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Nomothethic Approach In separate notebook"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}